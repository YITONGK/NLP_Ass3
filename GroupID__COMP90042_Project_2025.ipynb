{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/felikskong/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/felikskong/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/felikskong/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/felikskong/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "import faiss\n",
        "import nltk\n",
        "import spacy\n",
        "from lemminflect import getAllInflections\n",
        "from nltk.corpus import stopwords as nltk_stopwords, wordnet\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import CrossEncoder, InputExample, SentenceTransformer, losses\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertModel,\n",
        "    BertTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    logging as hf_logging\n",
        ")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Define file path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_claims_path = './data/train-claims.json'\n",
        "dev_claims_path = './data/dev-claims.json'\n",
        "evidence_path = './data/evidence.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Task 1 - Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step1: English keep 1207838/1208827\n",
            "Step2: Climate-related keep 385471/1207838\n"
          ]
        }
      ],
      "source": [
        "# ✅\n",
        "with open(train_claims_path, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_path, 'r') as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "all_nouns = []\n",
        "for claim_obj in train_claims.values():\n",
        "    doc = nlp(claim_obj[\"claim_text\"])\n",
        "    nouns = [token.lemma_.lower() for token in doc if token.pos_ == \"NOUN\"]\n",
        "    all_nouns.extend(nouns)\n",
        "\n",
        "top_keywords = set(word for word, _ in Counter(all_nouns).most_common(100))\n",
        "\n",
        "all_forms = set()\n",
        "for lemma in top_keywords:\n",
        "    all_forms.add(lemma)\n",
        "    infl_map = getAllInflections(lemma, upos=\"NOUN\")\n",
        "    for forms in infl_map.values():\n",
        "        all_forms.update(forms)\n",
        "\n",
        "def contains_climate_keywords(text: str, all_forms: set) -> bool:\n",
        "    words = re.findall(r\"\\b[a-z']+\\b\", text.lower())\n",
        "    return any(word in all_forms for word in words)\n",
        "\n",
        "\n",
        "def is_english(text: str, threshold: float = 0.5) -> bool:\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    if len(text) == 0:\n",
        "        return False\n",
        "    english_char_count = sum(1 for char in text if char.isalpha())\n",
        "    return (english_char_count / len(text)) >= threshold\n",
        "\n",
        "def clean_and_split(eid, text):\n",
        "    result_ids = []\n",
        "    result_texts = []\n",
        "    sentences = sent_tokenize(text)\n",
        "    for i, sent in enumerate(sentences):\n",
        "        sent = sent.lower()\n",
        "        sent = re.sub(r'[^a-z0-9\\s.,!?]', '', sent)\n",
        "        sent = re.sub(r'\\s+', ' ', sent).strip()\n",
        "        if len(sent.split()) >= 5:\n",
        "            result_ids.append(f\"{eid}_s{i}\")\n",
        "            result_texts.append(sent)\n",
        "    return result_ids, result_texts\n",
        "word_embedding_path = './word_embedding/evidence_embeddings.npy'\n",
        "word_embedding_meta_path = \"./word_embedding/evidence_meta.pkl\"\n",
        "\n",
        "\n",
        "with open(evidence_path, 'r') as f:\n",
        "    evidence_dict = json.load(f)\n",
        "eids  = list(evidence_dict.keys())\n",
        "texts = list(evidence_dict.values())\n",
        "english_pairs = [\n",
        "    (eid, txt)\n",
        "    for eid, txt in zip(eids, texts)\n",
        "    if is_english(txt)\n",
        "]\n",
        "print(f\"Step1: English keep {len(english_pairs)}/{len(texts)}\")\n",
        "\n",
        "climate_pairs = [\n",
        "    (eid, txt)\n",
        "    for eid, txt in english_pairs\n",
        "    if contains_climate_keywords(txt, all_forms)\n",
        "]\n",
        "print(f\"Step2: Climate-related keep {len(climate_pairs)}/{len(english_pairs)}\")\n",
        "\n",
        "\n",
        "cleaned_evidence_ids = []\n",
        "cleaned_evidence_texts = []\n",
        "original_evidence_ids = []\n",
        "\n",
        "for eid, text in climate_pairs:\n",
        "    cleaned_ids, cleaned_texts = clean_and_split(eid, text)\n",
        "    cleaned_evidence_ids.extend(cleaned_ids)\n",
        "    cleaned_evidence_texts.extend(cleaned_texts)\n",
        "    original_evidence_ids.extend([eid] * len(cleaned_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.4 Task 2 - Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4.1 Data Processing for BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "label2id = {\n",
        "    \"SUPPORTS\": 0,\n",
        "    \"REFUTES\": 1,\n",
        "    \"NOT_ENOUGH_INFO\": 2,\n",
        "    \"DISPUTED\": 3\n",
        "}\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, claims, evidence_dict, tokenizer, max_length=512):\n",
        "        self.encodings = []\n",
        "        self.labels = []\n",
        "        for claim_data in claims.values():\n",
        "            claim_text = claim_data[\"claim_text\"]\n",
        "            label_str = claim_data[\"claim_label\"]\n",
        "            for eid in claim_data.get(\"evidences\", []):\n",
        "                if eid in evidence_dict:\n",
        "                    evidence_text = evidence_dict[eid]\n",
        "                    encoded = tokenizer(\n",
        "                        claim_text,\n",
        "                        evidence_text,\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        max_length=max_length,\n",
        "                        return_tensors=\"pt\"\n",
        "                    )\n",
        "                    self.encodings.append({k: v.squeeze() for k, v in encoded.items()})\n",
        "                    self.labels.append(label2id[label_str])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.encodings[idx]\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "PAD, MASK = tokenizer.pad_token_id, tokenizer.mask_token_id\n",
        "\n",
        "label2id = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 claims: dict,\n",
        "                 evidence_dict: dict,\n",
        "                 tokenizer,\n",
        "                 max_length: int = 512,\n",
        "                 balance: bool = True,\n",
        "                 target_ratio: float = 1.0,\n",
        "                 augmenters=None,\n",
        "                 aug_params=None,\n",
        "                 seed: int = 42):\n",
        "\n",
        "        random.seed(seed)\n",
        "        self.tokenizer, self.max_length = tokenizer, max_length\n",
        "        self.encodings, self.labels = [], []\n",
        "        self.augmenters = set(augmenters or ['dropout', 'swap', 'pad', 'cutmix'])\n",
        "\n",
        "        _default = dict(dropout_prob=0.15,\n",
        "                        swap_prob=0.10,\n",
        "                        pad_prob=0.05,\n",
        "                        cutmix_min=0.3,\n",
        "                        cutmix_max=0.7)\n",
        "        self.aug_params = {**_default, **(aug_params or {})}\n",
        "\n",
        "        for cdict in claims.values():\n",
        "            claim_text = cdict[\"claim_text\"]\n",
        "            lab = label2id[cdict[\"claim_label\"]]\n",
        "            for eid in cdict.get(\"evidences\", []):\n",
        "                if eid in evidence_dict:\n",
        "                    evi = evidence_dict[eid]\n",
        "                    toks = tokenizer(claim_text, evi,\n",
        "                                     truncation=True,\n",
        "                                     padding=\"max_length\",\n",
        "                                     max_length=max_length,\n",
        "                                     return_tensors=\"pt\")\n",
        "                    self.encodings.append({k: v.squeeze(0) for k, v in toks.items()})\n",
        "                    self.labels.append(lab)\n",
        "\n",
        "        if balance:\n",
        "            self._balance_dataset(target_ratio)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {k: v.clone() for k, v in self.encodings[idx].items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def _balance_dataset(self, target_ratio: float):\n",
        "        by_label = defaultdict(list)\n",
        "        for i, y in enumerate(self.labels):\n",
        "            by_label[y].append(i)\n",
        "\n",
        "        max_count = int(max(len(v) for v in by_label.values()) * target_ratio)\n",
        "\n",
        "        for lab, idx_list in by_label.items():\n",
        "            need = max_count - len(idx_list)\n",
        "            for _ in range(max(0, need)):\n",
        "                base_idx = random.choice(idx_list)\n",
        "                base_enc = self.encodings[base_idx]\n",
        "                aug_enc = self._augment_encoding(base_enc, lab)\n",
        "                self.encodings.append(aug_enc)\n",
        "                self.labels.append(lab)\n",
        "\n",
        "    def _augment_encoding(self, enc, lab):\n",
        "        enc = {k: v.clone() for k, v in enc.items()} \n",
        "        choice = random.choice(list(self.augmenters))\n",
        "        if choice == 'dropout':\n",
        "            self._token_dropout(enc)\n",
        "        elif choice == 'swap':\n",
        "            self._swap_neighbor(enc)\n",
        "        elif choice == 'pad':\n",
        "            self._random_pad(enc)\n",
        "        elif choice == 'cutmix':\n",
        "            self._cutmix(enc, lab)\n",
        "        return enc\n",
        "\n",
        "    def _token_dropout(self, enc):\n",
        "        ids = enc['input_ids']\n",
        "        mask = torch.rand_like(ids.float()) < self.aug_params['dropout_prob']\n",
        "        ids[mask & (ids != PAD)] = MASK\n",
        "        enc['input_ids'] = ids\n",
        "\n",
        "    def _swap_neighbor(self, enc):\n",
        "        ids = enc['input_ids']\n",
        "        for i in range(1, len(ids) - 1):\n",
        "            if random.random() < self.aug_params['swap_prob'] and ids[i] not in (PAD, MASK):\n",
        "                ids[i], ids[i + 1] = ids[i + 1].clone(), ids[i].clone()\n",
        "        enc['input_ids'] = ids\n",
        "\n",
        "    def _random_pad(self, enc):\n",
        "        ids, mask = enc['input_ids'], enc['attention_mask']\n",
        "        pad_prob = self.aug_params['pad_prob']\n",
        "        new_ids, new_mask = [], []\n",
        "        for tok, m in zip(ids, mask):\n",
        "            if m.item() == 0:  \n",
        "                break\n",
        "            new_ids.append(tok.item())\n",
        "            new_mask.append(1)\n",
        "            if random.random() < pad_prob and len(new_ids) < self.max_length - 1:\n",
        "                new_ids.append(PAD)\n",
        "                new_mask.append(0)\n",
        "        new_ids = (new_ids + [PAD] * self.max_length)[:self.max_length]\n",
        "        new_mask = (new_mask + [0] * self.max_length)[:self.max_length]\n",
        "        enc['input_ids'] = torch.tensor(new_ids, dtype=torch.long)\n",
        "        enc['attention_mask'] = torch.tensor(new_mask, dtype=torch.long)\n",
        "\n",
        "    def _cutmix(self, enc, lab):\n",
        "        same_idxs = [i for i, y in enumerate(self.labels) if y == lab]\n",
        "        other = {k: v.clone() for k, v in self.encodings[random.choice(same_idxs)].items()}\n",
        "        lam = random.uniform(self.aug_params['cutmix_min'],\n",
        "                             self.aug_params['cutmix_max'])\n",
        "        cut_point = int(lam * self.max_length)\n",
        "        enc['input_ids'][cut_point:] = other['input_ids'][cut_point:]\n",
        "        enc['attention_mask'][cut_point:] = other['attention_mask'][cut_point:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4.2 Data Processing for RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "MAX_LEN = 50\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def lemmatize(word):\n",
        "    lemma = lemmatizer.lemmatize(word, 'v')\n",
        "    return lemmatizer.lemmatize(lemma, 'n')\n",
        "\n",
        "def preprocess(text, remove_stopwords=True, lemma=True, stem=False):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if re.match('^[a-zA-Z0-9-]+$', t)]\n",
        "    if remove_stopwords:\n",
        "        tokens = [t for t in tokens if t not in stopwords]\n",
        "    if lemma:\n",
        "        tokens = [lemmatize(t) for t in tokens]\n",
        "    if stem:\n",
        "        tokens = [stemmer.stem(t) for t in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def load_data(claims_file, evidence_file):\n",
        "    with open(claims_file, 'r', encoding='utf-8') as f:\n",
        "        claims_data = json.load(f)\n",
        "    with open(evidence_file, 'r', encoding='utf-8') as f:\n",
        "        evid_data = json.load(f)\n",
        "    \n",
        "    claim_texts, evid_texts, labels = [], [], []\n",
        "    for cid, cdata in claims_data.items():\n",
        "        claim = preprocess(cdata['claim_text'])\n",
        "        evid_ids = cdata['evidences']\n",
        "        evids = ' '.join([evid_data.get(eid, '') for eid in evid_ids])\n",
        "        evid = preprocess(evids)\n",
        "        claim_texts.append(claim)\n",
        "        evid_texts.append(evid)\n",
        "        labels.append(cdata['claim_label'])\n",
        "    \n",
        "    df = pd.DataFrame({\n",
        "        'claim': claim_texts,\n",
        "        'evidence': evid_texts,\n",
        "        'label': labels\n",
        "    })\n",
        "    return df\n",
        "\n",
        "train_df = load_data(train_claims_path, evidence_path)\n",
        "dev_df = load_data(dev_claims_path, evidence_path)\n",
        "\n",
        "all_text = train_df['claim'].tolist() + train_df['evidence'].tolist()\n",
        "token_counts = Counter(w for text in all_text for w in text.split())\n",
        "vocab = {w: idx+1 for idx, (w, _) in enumerate(token_counts.items())}\n",
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "def text_to_seq(text):\n",
        "    seq = [vocab.get(w, 0) for w in text.split()]\n",
        "    return seq + [0]*(MAX_LEN - len(seq)) if len(seq) < MAX_LEN else seq[:MAX_LEN]\n",
        "\n",
        "train_claims = [text_to_seq(t) for t in train_df['claim']]\n",
        "train_evids = [text_to_seq(t) for t in train_df['evidence']]\n",
        "dev_claims = [text_to_seq(t) for t in dev_df['claim']]\n",
        "dev_evids = [text_to_seq(t) for t in dev_df['evidence']]\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "train_labels = label_enc.fit_transform(train_df['label'])\n",
        "dev_labels = label_enc.transform(dev_df['label'])\n",
        "\n",
        "class ClaimDataset(Dataset):\n",
        "    def __init__(self, claims, evidences, labels):\n",
        "        self.claims = torch.tensor(claims, dtype=torch.long)\n",
        "        self.evidences = torch.tensor(evidences, dtype=torch.long)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.claims[idx], self.evidences[idx], self.labels[idx]\n",
        "\n",
        "train_ds = ClaimDataset(train_claims, train_evids, train_labels)\n",
        "dev_ds = ClaimDataset(dev_claims, dev_evids, dev_labels)\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dev_dl = DataLoader(dev_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "class SelfAttentionPooling(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = torch.softmax(self.attention(x), dim=1)\n",
        "        pooled = torch.sum(weights * x, dim=1)\n",
        "        return pooled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.1 Train MiniLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training pairs: 4122\n",
            "Missing evidence ids: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 129/129 [01:06<00:00,  1.93it/s]\n",
            "Iteration: 100%|██████████| 129/129 [00:43<00:00,  2.98it/s]\n",
            "Iteration: 100%|██████████| 129/129 [00:39<00:00,  3.27it/s]\n",
            "Iteration: 100%|██████████| 129/129 [00:41<00:00,  3.13it/s]\n",
            "Iteration: 100%|██████████| 129/129 [00:42<00:00,  3.05it/s]\n",
            "Epoch: 100%|██████████| 5/5 [03:53<00:00, 46.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finetuned model saved.\n"
          ]
        }
      ],
      "source": [
        "# ✅\n",
        "with open(train_claims_path, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_path, 'r') as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "train_samples = []\n",
        "missed = 0\n",
        "\n",
        "for claim in train_claims.values():\n",
        "    claim_text = claim['claim_text']\n",
        "    evidence_ids = claim.get('evidences', [])\n",
        "    for eid in evidence_ids:\n",
        "        if eid in evidence_dict:\n",
        "            ev_text = evidence_dict[eid]\n",
        "            train_samples.append(InputExample(texts=[claim_text, ev_text], label=1.0))\n",
        "        else:\n",
        "            missed += 1\n",
        "\n",
        "\n",
        "print(f\"Total training pairs: {len(train_samples)}\")\n",
        "print(f\"Missing evidence ids: {missed}\")\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=32)\n",
        "\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
        "\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=5,\n",
        "    warmup_steps=100,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "model.save('./model/my_finetuned_minilm_retriever')\n",
        "print(\"Finetuned model saved.\")\n",
        "\n",
        "print(\"\"\"\n",
        "Total training pairs: 4122\n",
        "Missing evidence ids: 0\n",
        "Iteration: 100%|██████████| 129/129 [01:06<00:00,  1.93it/s]\n",
        "Iteration: 100%|██████████| 129/129 [00:43<00:00,  2.98it/s]\n",
        "Iteration: 100%|██████████| 129/129 [00:39<00:00,  3.27it/s]\n",
        "Iteration: 100%|██████████| 129/129 [00:41<00:00,  3.13it/s]\n",
        "Iteration: 100%|██████████| 129/129 [00:42<00:00,  3.05it/s]\n",
        "Epoch: 100%|██████████| 5/5 [03:53<00:00, 46.64s/it]\n",
        "Finetuned model saved.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.2 Train Msmarco Reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training samples: 8244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 516/516 [01:09<00:00,  7.41it/s]\n",
            "Iteration: 100%|██████████| 516/516 [01:05<00:00,  7.89it/s]\n",
            "Iteration: 100%|██████████| 516/516 [01:12<00:00,  7.11it/s]\n",
            "Iteration: 100%|██████████| 516/516 [01:11<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 516/516 [01:11<00:00,  7.20it/s]\n",
            "Epoch: 100%|██████████| 5/5 [05:50<00:00, 70.05s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finetuned model saved.\n"
          ]
        }
      ],
      "source": [
        "# ✅\n",
        "with open(train_claims_path, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_path, 'r') as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "train_samples = []\n",
        "\n",
        "def generate_samples(claims_data):\n",
        "    samples = []\n",
        "    for claim in claims_data.values():\n",
        "        claim_text = claim[\"claim_text\"]\n",
        "        evidence_ids = claim.get(\"evidences\", [])\n",
        "        pos_evidence_texts = [evidence_dict[eid] for eid in evidence_ids if eid in evidence_dict]\n",
        "\n",
        "        for ev in pos_evidence_texts:\n",
        "            samples.append(InputExample(texts=[claim_text, ev], label=1.0))\n",
        "\n",
        "        neg_pool = [e for eid, e in evidence_dict.items() if eid not in evidence_ids]\n",
        "        for _ in range(len(pos_evidence_texts)):\n",
        "            neg_ev = random.choice(neg_pool)\n",
        "            samples.append(InputExample(texts=[claim_text, neg_ev], label=0.0))\n",
        "\n",
        "    return samples\n",
        "\n",
        "train_samples.extend(generate_samples(train_claims))\n",
        "\n",
        "print(f\"Total training samples: {len(train_samples)}\")\n",
        "\n",
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=16)\n",
        "\n",
        "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\", num_labels=1)\n",
        "\n",
        "model.fit(\n",
        "    train_dataloader=train_dataloader,\n",
        "    epochs=5,\n",
        "    warmup_steps=100,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "model.save('./model/my_finetuned_msmarco_reranker')\n",
        "print(\"Finetuned model saved.\")\n",
        "\n",
        "print(\"\"\"\n",
        "Total training samples: 8244\n",
        "Iteration: 100%|██████████| 516/516 [01:09<00:00,  7.41it/s]\n",
        "Iteration: 100%|██████████| 516/516 [01:05<00:00,  7.89it/s]\n",
        "Iteration: 100%|██████████| 516/516 [01:12<00:00,  7.11it/s]\n",
        "Iteration: 100%|██████████| 516/516 [01:11<00:00,  7.27it/s]\n",
        "Iteration: 100%|██████████| 516/516 [01:11<00:00,  7.20it/s]\n",
        "Epoch: 100%|██████████| 5/5 [05:50<00:00, 70.05s/it]\n",
        "Finetuned model saved.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.3 Load Finetuned models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅\n",
        "model = SentenceTransformer('./model/my_finetuned_minilm_retriever')\n",
        "reranker =  CrossEncoder('./model/my_finetuned_msmarco_reranker')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1.4 Encode Evidence Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 12133/12133 [05:59<00:00, 33.76it/s]\n"
          ]
        }
      ],
      "source": [
        "# ✅\n",
        "evidence_embeddings = model.encode(\n",
        "    cleaned_evidence_texts,\n",
        "    convert_to_numpy=True,\n",
        "    normalize_embeddings= True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "\n",
        "os.makedirs(\"./word_embedding\", exist_ok=True)\n",
        "np.save(word_embedding_path, evidence_embeddings)\n",
        "\n",
        "with open(word_embedding_meta_path, \"wb\") as f:\n",
        "    pickle.dump((cleaned_evidence_ids, cleaned_evidence_texts, original_evidence_ids), f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.1 BERT Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"./model/my_bert_classifier\"\n",
        "\n",
        "with open(train_claims_path, 'r') as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(evidence_path, 'r') as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "train_dataset = train_dataset = ClaimEvidenceDataset(\n",
        "    claims=train_claims,\n",
        "    evidence_dict=evidence_dict,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=512,\n",
        "    balance=True,             \n",
        "    target_ratio=1.0,\n",
        ")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_strategy=\"no\",   \n",
        "    logging_steps=50,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.2 Train RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMBED_DIM = 100\n",
        "HIDDEN_DIM = 64\n",
        "NUM_CLASSES = 4\n",
        "DROPOUT_PROB = 0.4\n",
        "EPOCHS = 20\n",
        "LR = 1e-4\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "if torch.cuda.is_available(): \n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.embed_dropout = nn.Dropout(DROPOUT_PROB)\n",
        "        self.rnn_claim = nn.RNN(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.rnn_evid = nn.RNN(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.rnn_dropout = nn.Dropout(DROPOUT_PROB)\n",
        "        self.attention_claim = SelfAttentionPooling(hidden_dim * 2)\n",
        "        self.attention_evid = SelfAttentionPooling(hidden_dim * 2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 4, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(DROPOUT_PROB),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, claim, evidence):\n",
        "        claim_emb = self.embed_dropout(self.embedding(claim))\n",
        "        evid_emb = self.embed_dropout(self.embedding(evidence))\n",
        "        \n",
        "        claim_out, _ = self.rnn_claim(claim_emb)\n",
        "        evid_out, _ = self.rnn_evid(evid_emb)\n",
        "        \n",
        "        claim_out = self.rnn_dropout(claim_out)\n",
        "        evid_out = self.rnn_dropout(evid_out)\n",
        "        \n",
        "        claim_pool = self.attention_claim(claim_out)\n",
        "        evid_pool = self.attention_evid(evid_out)\n",
        "        \n",
        "        combined = torch.cat([claim_pool, evid_pool], dim=1)\n",
        "        return self.classifier(combined)\n",
        "\n",
        "model = RNNModel(vocab_size, EMBED_DIM, HIDDEN_DIM, NUM_CLASSES).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 20/20 [00:01<00:00, 12.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 4.6202, Train Acc: 0.3542\n",
            "Val Loss: 1.3208, Val Acc: 0.4416\n",
            "✅ New best model saved (epoch 1, acc 44.1558%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 20/20 [00:01<00:00, 12.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.2437, Train Acc: 0.4015\n",
            "Val Loss: 1.3139, Val Acc: 0.4416\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 20/20 [00:01<00:00, 12.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.2604, Train Acc: 0.4251\n",
            "Val Loss: 1.3084, Val Acc: 0.4286\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 20/20 [00:01<00:00, 12.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.2710, Train Acc: 0.4357\n",
            "Val Loss: 1.3071, Val Acc: 0.4351\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 20/20 [00:01<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.7899, Train Acc: 0.4316\n",
            "Val Loss: 1.3043, Val Acc: 0.4221\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 20/20 [00:01<00:00, 12.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.1248, Train Acc: 0.4438\n",
            "Val Loss: 1.3016, Val Acc: 0.4221\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 20/20 [00:01<00:00, 12.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.4566, Train Acc: 0.4226\n",
            "Val Loss: 1.3015, Val Acc: 0.4416\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 20/20 [00:01<00:00, 12.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.8482, Train Acc: 0.4202\n",
            "Val Loss: 1.2984, Val Acc: 0.4091\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 20/20 [00:01<00:00, 12.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.6763, Train Acc: 0.4226\n",
            "Val Loss: 1.2941, Val Acc: 0.3896\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 20/20 [00:01<00:00, 12.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.8144, Train Acc: 0.4349\n",
            "Val Loss: 1.2938, Val Acc: 0.3636\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11: 100%|██████████| 20/20 [00:01<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9803, Train Acc: 0.4332\n",
            "Val Loss: 1.2903, Val Acc: 0.3636\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12: 100%|██████████| 20/20 [00:01<00:00, 11.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.8918, Train Acc: 0.4381\n",
            "Val Loss: 1.2863, Val Acc: 0.4026\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13: 100%|██████████| 20/20 [00:01<00:00, 12.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 3.0893, Train Acc: 0.4308\n",
            "Val Loss: 1.2822, Val Acc: 0.3961\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14: 100%|██████████| 20/20 [00:01<00:00, 12.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.9196, Train Acc: 0.4397\n",
            "Val Loss: 1.2775, Val Acc: 0.4091\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15: 100%|██████████| 20/20 [00:01<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.8342, Train Acc: 0.4357\n",
            "Val Loss: 1.2779, Val Acc: 0.3247\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16: 100%|██████████| 20/20 [00:01<00:00, 12.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.4624, Train Acc: 0.4397\n",
            "Val Loss: 1.2746, Val Acc: 0.3506\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17: 100%|██████████| 20/20 [00:01<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.3187, Train Acc: 0.4650\n",
            "Val Loss: 1.2735, Val Acc: 0.3182\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18: 100%|██████████| 20/20 [00:01<00:00, 12.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.5657, Train Acc: 0.4658\n",
            "Val Loss: 1.2731, Val Acc: 0.2597\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19: 100%|██████████| 20/20 [00:01<00:00, 12.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.2013, Train Acc: 0.4894\n",
            "Val Loss: 1.2727, Val Acc: 0.2403\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20: 100%|██████████| 20/20 [00:01<00:00, 12.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.4498, Train Acc: 0.4634\n",
            "Val Loss: 1.2719, Val Acc: 0.2468\n",
            "\n"
          ]
        }
      ],
      "source": [
        "label2idx = {\n",
        "    \"SUPPORTS\": 0,\n",
        "    \"REFUTES\": 1,\n",
        "    \"NOT_ENOUGH_INFO\": 2,\n",
        "    \"DISPUTED\": 3\n",
        "}\n",
        "\n",
        "with open(train_claims_path, 'r', encoding='utf-8') as f:\n",
        "    train_claim = json.load(f)\n",
        "\n",
        "label_counts = Counter([label2idx[obj[\"claim_label\"]] for obj in train_claim.values()])\n",
        "total = sum(label_counts.values())\n",
        "\n",
        "class_weights = [total / label_counts[i] for i in range(len(label2idx))]\n",
        "\n",
        "weights = torch.tensor(class_weights, dtype=torch.float).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "best_acc = 0.0\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    total_loss, total_correct = 0, 0\n",
        "    for claim, evid, label in tqdm(train_dl, desc=f\"Epoch {epoch}\"):\n",
        "        claim, evid, label = claim.to(DEVICE), evid.to(DEVICE), label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(claim, evid)\n",
        "        loss = criterion(out, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        total_correct += (out.argmax(1) == label).sum().item()\n",
        "    acc = total_correct / len(train_ds)\n",
        "    print(f\"Train Loss: {total_loss/len(train_dl):.4f}, Train Acc: {acc:.4f}\")\n",
        "    \n",
        "    model.eval()\n",
        "    val_loss, val_correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for claim, evid, label in dev_dl:\n",
        "            claim, evid, label = claim.to(DEVICE), evid.to(DEVICE), label.to(DEVICE)\n",
        "            out = model(claim, evid)\n",
        "            loss = criterion(out, label)\n",
        "            val_loss += loss.item()\n",
        "            val_correct += (out.argmax(1) == label).sum().item()\n",
        "    val_acc = val_correct / len(dev_ds)\n",
        "    print(f\"Val Loss: {val_loss/len(dev_dl):.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"rnn_model.pth\")\n",
        "        print(f\"✅ New best model saved (epoch {epoch}, acc {val_acc:.4%})\\n\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "import pickle\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_enc, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.3 Train LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BiLSTMWithBertEncoder(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout_bert): Dropout(p=0.2, inplace=False)\n",
              "  (lstm): LSTM(768, 512, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
              "  (attn_fc): Linear(in_features=1024, out_features=1, bias=True)\n",
              "  (dropout_pool): Dropout(p=0.2, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ✅\n",
        "BERT_MODEL     = \"bert-base-uncased\"\n",
        "MAX_LEN        = 256\n",
        "LSTM_HID_DIM   = 512\n",
        "NUM_CLASSES    = 4\n",
        "DROPOUT_PROB   = 0.2\n",
        "NUM_LAYERS     = 3\n",
        "BATCH_SIZE     = 16\n",
        "EPOCHS         = 10\n",
        "LR             = 2e-4\n",
        "\n",
        "DEVICE = \"cpu\"\n",
        "if torch.cuda.is_available(): \n",
        "    DEVICE = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "    \n",
        "label2idx = {\n",
        "    \"SUPPORTS\":         0,\n",
        "    \"REFUTES\":          1,\n",
        "    \"NOT_ENOUGH_INFO\":  2,\n",
        "    \"DISPUTED\":         3,\n",
        "}\n",
        "\n",
        "with open(train_claims_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_claims = json.load(f)\n",
        "with open(dev_claims_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    dev_claims = json.load(f)\n",
        "with open(evidence_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, claims, evidences, tokenizer, max_len):\n",
        "        self.items = []\n",
        "        for cid, obj in claims.items():\n",
        "            claim_text = obj[\"claim_text\"]\n",
        "            ev_ids     = obj.get(\"evidences\", [])\n",
        "            ev_texts   = [evidences[e] for e in ev_ids if e in evidences]\n",
        "            full_input = claim_text + \" [SEP] \" + \" \".join(ev_texts)\n",
        "            label = label2idx[obj[\"claim_label\"]]\n",
        "            self.items.append((full_input, label))\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len   = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text, label = self.items[idx]\n",
        "        enc = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return (\n",
        "            enc[\"input_ids\"].squeeze(0),\n",
        "            enc[\"attention_mask\"].squeeze(0),\n",
        "            torch.tensor(label, dtype=torch.long),\n",
        "        )\n",
        "\n",
        "def collate_batch(batch):\n",
        "    ids, masks, labs = zip(*batch)\n",
        "    return torch.stack(ids), torch.stack(masks), torch.stack(labs)\n",
        "\n",
        "train_ds = ClaimEvidenceDataset(train_claims, evidence_dict, tokenizer, MAX_LEN)\n",
        "dev_ds   = ClaimEvidenceDataset(dev_claims,   evidence_dict, tokenizer, MAX_LEN)\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "    collate_fn=collate_batch, num_workers=0, pin_memory=True\n",
        ")\n",
        "dev_dl   = DataLoader(\n",
        "    dev_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "    collate_fn=collate_batch, num_workers=0, pin_memory=True\n",
        ")\n",
        "\n",
        "class BiLSTMWithBertEncoder(nn.Module):\n",
        "    def __init__(self, bert_name, lstm_hid, num_classes, \n",
        "                 dropout_prob, lstm_layers):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_name)\n",
        "        for p in self.bert.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        bert_dim = self.bert.config.hidden_size\n",
        "\n",
        "        self.dropout_bert = nn.Dropout(dropout_prob)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size    = bert_dim,\n",
        "            hidden_size   = lstm_hid,\n",
        "            num_layers    = lstm_layers,\n",
        "            batch_first   = True,\n",
        "            bidirectional = True,\n",
        "            dropout       = dropout_prob\n",
        "        )\n",
        "\n",
        "        self.attn_fc = nn.Linear(2 * lstm_hid, 1)\n",
        "\n",
        "        self.dropout_pool = nn.Dropout(dropout_prob)\n",
        "\n",
        "        self.classifier = nn.Linear(2 * lstm_hid, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        seq_emb  = bert_out.last_hidden_state \n",
        "        seq_emb  = self.dropout_bert(seq_emb)\n",
        "\n",
        "        lstm_out, _ = self.lstm(seq_emb)\n",
        "\n",
        "        scores = self.attn_fc(lstm_out).squeeze(-1)\n",
        "        scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
        "        alphas = torch.softmax(scores, dim=1)\n",
        "        pooled = torch.sum(lstm_out * alphas.unsqueeze(-1), dim=1)\n",
        "\n",
        "        pooled = self.dropout_pool(pooled)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits\n",
        "    \n",
        "model = BiLSTMWithBertEncoder(BERT_MODEL, LSTM_HID_DIM, NUM_CLASSES, DROPOUT_PROB, NUM_LAYERS)\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 1: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 1 Avg Loss: 1.2819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 44.1558%\n",
            "✅ New best model saved (epoch 1, acc 44.1558%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 2: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 2 Avg Loss: 1.2243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 45.4545%\n",
            "✅ New best model saved (epoch 2, acc 45.4545%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 3: 100%|██████████| 77/77 [00:41<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 3 Avg Loss: 1.2018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 46.1039%\n",
            "✅ New best model saved (epoch 3, acc 46.1039%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 4: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 4 Avg Loss: 1.1856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 48.7013%\n",
            "✅ New best model saved (epoch 4, acc 48.7013%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 5: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 5 Avg Loss: 1.1661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 51.2987%\n",
            "✅ New best model saved (epoch 5, acc 51.2987%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 6: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 6 Avg Loss: 1.1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 50.6494%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 7: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 7 Avg Loss: 1.1397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 51.9481%\n",
            "✅ New best model saved (epoch 7, acc 51.9481%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 8: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 8 Avg Loss: 1.1269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 53.2468%\n",
            "✅ New best model saved (epoch 8, acc 53.2468%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 9: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 9 Avg Loss: 1.1130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 54.5455%\n",
            "✅ New best model saved (epoch 9, acc 54.5455%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 10: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Epoch 10 Avg Loss: 1.1044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Dev Accuracy: 53.8961%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ✅\n",
        "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc = 0.0\n",
        "BEST_MODEL_PATH = \"task2_best_lstm.pt\"\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for input_ids, attn_mask, labels in tqdm(train_dl, desc=f\"Train Epoch {epoch}\"):\n",
        "        input_ids = input_ids.to(DEVICE)\n",
        "        attn_mask = attn_mask.to(DEVICE)\n",
        "        labels    = labels.to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids, attn_mask)\n",
        "        loss   = criterion(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dl)\n",
        "    print(f\"→ Epoch {epoch} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total   = 0\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attn_mask, labels in tqdm(dev_dl, desc=\" Eval\"):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attn_mask = attn_mask.to(DEVICE)\n",
        "            labels    = labels.to(DEVICE)\n",
        "\n",
        "            preds = model(input_ids, attn_mask).argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    print(f\"→ Dev Accuracy: {acc:.4%}\")\n",
        "\n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        print(f\"✅ New best model saved (epoch {epoch}, acc {acc:.4%})\\n\")\n",
        "    else:\n",
        "        print()\n",
        "\n",
        "print(\"\"\"\n",
        "Train Epoch 1: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n",
        "→ Epoch 1 Avg Loss: 1.2819\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]\n",
        "→ Dev Accuracy: 44.1558%\n",
        "✅ New best model saved (epoch 1, acc 44.1558%)\n",
        "\n",
        "Train Epoch 2: 100%|██████████| 77/77 [00:41<00:00,  1.87it/s]\n",
        "→ Epoch 2 Avg Loss: 1.2243\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.17it/s]\n",
        "→ Dev Accuracy: 45.4545%\n",
        "✅ New best model saved (epoch 2, acc 45.4545%)\n",
        "\n",
        "Train Epoch 3: 100%|██████████| 77/77 [00:41<00:00,  1.88it/s]\n",
        "→ Epoch 3 Avg Loss: 1.2018\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n",
        "→ Dev Accuracy: 46.1039%\n",
        "✅ New best model saved (epoch 3, acc 46.1039%)\n",
        "\n",
        "Train Epoch 4: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 4 Avg Loss: 1.1856\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n",
        "→ Dev Accuracy: 48.7013%\n",
        "✅ New best model saved (epoch 4, acc 48.7013%)\n",
        "\n",
        "Train Epoch 5: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 5 Avg Loss: 1.1661\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.31it/s]\n",
        "→ Dev Accuracy: 51.2987%\n",
        "✅ New best model saved (epoch 5, acc 51.2987%)\n",
        "\n",
        "Train Epoch 6: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 6 Avg Loss: 1.1500\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n",
        "→ Dev Accuracy: 50.6494%\n",
        "\n",
        "Train Epoch 7: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 7 Avg Loss: 1.1397\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.31it/s]\n",
        "→ Dev Accuracy: 51.9481%\n",
        "✅ New best model saved (epoch 7, acc 51.9481%)\n",
        "\n",
        "Train Epoch 8: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 8 Avg Loss: 1.1269\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.29it/s]\n",
        "→ Dev Accuracy: 53.2468%\n",
        "✅ New best model saved (epoch 8, acc 53.2468%)\n",
        "\n",
        "Train Epoch 9: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 9 Avg Loss: 1.1130\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.28it/s]\n",
        "→ Dev Accuracy: 54.5455%\n",
        "✅ New best model saved (epoch 9, acc 54.5455%)\n",
        "\n",
        "Train Epoch 10: 100%|██████████| 77/77 [00:40<00:00,  1.91it/s]\n",
        "→ Epoch 10 Avg Loss: 1.1044\n",
        " Eval: 100%|██████████| 10/10 [00:03<00:00,  3.30it/s]\n",
        "→ Dev Accuracy: 53.8961%\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating best model: 100%|██████████| 10/10 [00:03<00:00,  2.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Reloaded Best Model Accuracy: 54.5455%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = BiLSTMWithBertEncoder(\n",
        "    bert_name=BERT_MODEL,\n",
        "    lstm_hid=LSTM_HID_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    dropout_prob=DROPOUT_PROB,\n",
        "    lstm_layers=NUM_LAYERS,\n",
        ")\n",
        "model.load_state_dict(torch.load(\"task2_best_lstm.pt\", map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "dev_ds = ClaimEvidenceDataset(dev_claims, evidence_dict, tokenizer, MAX_LEN)\n",
        "dev_dl = DataLoader(\n",
        "    dev_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    collate_fn=collate_batch, num_workers=0, pin_memory=True\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "preds, labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input_ids, attn_mask, batch_labels in tqdm(dev_dl, desc=\"Evaluating best model\"):\n",
        "        input_ids = input_ids.to(DEVICE)\n",
        "        attn_mask = attn_mask.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids, attn_mask)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "\n",
        "        preds.extend(pred.cpu().numpy())\n",
        "        labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(labels, preds)\n",
        "print(f\"🎯 Reloaded Best Model Accuracy: {acc:.4%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.4 Ensembled Model Using Soft Vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_LEN = 256\n",
        "id2label = {0: \"SUPPORTS\", 1: \"REFUTES\", 2: \"NOT_ENOUGH_INFO\", 3: \"DISPUTED\"}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "with open(evidence_path, \"r\") as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"model/my_bert_classifier\").to(DEVICE)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"model/my_bert_classifier\")\n",
        "bert_model.eval()\n",
        "\n",
        "class BiLSTMWithBertEncoder(torch.nn.Module):\n",
        "    def __init__(self, bert_name, lstm_hid, num_classes, dropout_prob, lstm_layers):\n",
        "        super().__init__()\n",
        "        from transformers import AutoModel\n",
        "        self.bert = AutoModel.from_pretrained(bert_name)\n",
        "        for p in self.bert.parameters():\n",
        "            p.requires_grad = False\n",
        "        bert_dim = self.bert.config.hidden_size\n",
        "        self.dropout_bert = torch.nn.Dropout(dropout_prob)\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            input_size=bert_dim,\n",
        "            hidden_size=lstm_hid,\n",
        "            num_layers=lstm_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=dropout_prob\n",
        "        )\n",
        "        self.attn_fc = torch.nn.Linear(2 * lstm_hid, 1)\n",
        "        self.dropout_pool = torch.nn.Dropout(dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(2 * lstm_hid, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        seq_emb = self.dropout_bert(bert_out.last_hidden_state)\n",
        "        lstm_out, _ = self.lstm(seq_emb)\n",
        "        scores = self.attn_fc(lstm_out).squeeze(-1)\n",
        "        scores = scores.masked_fill(attention_mask == 0, -1e9)\n",
        "        alphas = torch.softmax(scores, dim=1)\n",
        "        pooled = torch.sum(lstm_out * alphas.unsqueeze(-1), dim=1)\n",
        "        pooled = self.dropout_pool(pooled)\n",
        "        logits = self.classifier(pooled)\n",
        "        return logits\n",
        "\n",
        "BERT_MODEL = \"bert-base-uncased\"\n",
        "LSTM_HID_DIM = 512\n",
        "NUM_CLASSES = 4\n",
        "DROPOUT_PROB = 0.2\n",
        "NUM_LAYERS = 3\n",
        "\n",
        "bilstm_model = BiLSTMWithBertEncoder(BERT_MODEL, LSTM_HID_DIM, NUM_CLASSES, DROPOUT_PROB, NUM_LAYERS).to(DEVICE)\n",
        "bilstm_model.load_state_dict(torch.load(\"task2_best_model.pt\", map_location=DEVICE))\n",
        "bilstm_model.eval()\n",
        "bilstm_tokenizer = bert_tokenizer\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_LEN = 50\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_DIM = 64\n",
        "NUM_CLASSES = 4\n",
        "DROPOUT_PROB = 0.4\n",
        "vocab_size = 1\n",
        "\n",
        "stopwords = set(nltk_stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def lemmatize(word):\n",
        "    lemma = lemmatizer.lemmatize(word, 'v')\n",
        "    return lemmatizer.lemmatize(lemma, 'n')\n",
        "\n",
        "def preprocess(text, remove_stopwords=True, lemma=True, stem=False):\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [t for t in tokens if re.match('^[a-zA-Z0-9-]+$', t)]\n",
        "    if remove_stopwords:\n",
        "        tokens = [t for t in tokens if t not in stopwords]\n",
        "    if lemma:\n",
        "        tokens = [lemmatize(t) for t in tokens]\n",
        "    if stem:\n",
        "        tokens = [stemmer.stem(t) for t in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def text_to_seq(text):\n",
        "    tokens = text.split()\n",
        "    seq = [vocab.get(t, 0) for t in tokens]\n",
        "    return seq + [0] * (MAX_LEN - len(seq)) if len(seq) < MAX_LEN else seq[:MAX_LEN]\n",
        "\n",
        "class SelfAttentionPooling(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.attention = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = torch.softmax(self.attention(x), dim=1)\n",
        "        pooled = torch.sum(weights * x, dim=1)\n",
        "        return pooled\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.embed_dropout = nn.Dropout(DROPOUT_PROB)\n",
        "        self.rnn_claim = nn.RNN(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.rnn_evid = nn.RNN(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.rnn_dropout = nn.Dropout(DROPOUT_PROB)\n",
        "        self.attention_claim = SelfAttentionPooling(hidden_dim * 2)\n",
        "        self.attention_evid = SelfAttentionPooling(hidden_dim * 2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 4, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(DROPOUT_PROB),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, claim, evidence):\n",
        "        claim_emb = self.embed_dropout(self.embedding(claim))\n",
        "        evid_emb = self.embed_dropout(self.embedding(evidence))\n",
        "\n",
        "        claim_out, _ = self.rnn_claim(claim_emb)\n",
        "        evid_out, _ = self.rnn_evid(evid_emb)\n",
        "\n",
        "        claim_out = self.rnn_dropout(claim_out)\n",
        "        evid_out = self.rnn_dropout(evid_out)\n",
        "\n",
        "        claim_pool = self.attention_claim(claim_out)\n",
        "        evid_pool = self.attention_evid(evid_out)\n",
        "\n",
        "        combined = torch.cat([claim_pool, evid_pool], dim=1)\n",
        "        return self.classifier(combined)\n",
        "\n",
        "with open(train_claims_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    train_data = json.load(f)\n",
        "with open(evidence_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    evidence_dict = json.load(f)\n",
        "\n",
        "all_text = []\n",
        "for item in train_data.values():\n",
        "    claim = preprocess(item[\"claim_text\"])\n",
        "    evids = ' '.join([evidence_dict.get(eid, '') for eid in item[\"evidences\"]])\n",
        "    ev_text = preprocess(evids)\n",
        "    all_text.extend(claim.split() + ev_text.split())\n",
        "\n",
        "token_counts = Counter(all_text)\n",
        "vocab = {w: idx + 1 for idx, (w, _) in enumerate(token_counts.items())}\n",
        "vocab_size = len(vocab) + 1\n",
        "\n",
        "rnn_model = RNNModel(vocab_size, EMBED_DIM, HIDDEN_DIM, NUM_CLASSES).to(DEVICE)\n",
        "rnn_model.load_state_dict(torch.load(\"rnn_model.pth\", map_location=DEVICE))\n",
        "rnn_model.eval()\n",
        "\n",
        "with open(\"label_encoder.pkl\", \"rb\") as f:\n",
        "    label_enc = pickle.load(f)\n",
        "\n",
        "def get_bert_probs(claim, evid_ids):\n",
        "    evids = \" \".join([evidence_dict.get(eid, \"\") for eid in evid_ids])\n",
        "    inputs = bert_tokenizer(claim, evids, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = bert_model(**inputs).logits\n",
        "        probs = F.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "    return np.array(probs)\n",
        "\n",
        "def get_bilstm_probs(claim, evid_ids):\n",
        "    evids = \" \".join([evidence_dict.get(eid, \"\") for eid in evid_ids])\n",
        "    inputs = bilstm_tokenizer(claim, evids, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"pt\").to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = bilstm_model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
        "    return F.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "\n",
        "def get_rnn_probs(claim, evid_ids):\n",
        "    claim_text = preprocess(claim)\n",
        "    evid_text = \" \".join([evidence_dict.get(eid, \"\") for eid in evid_ids])\n",
        "    evid_text = preprocess(evid_text)\n",
        "    claim_seq = text_to_seq(claim_text)\n",
        "    evid_seq = text_to_seq(evid_text)\n",
        "    claim_tensor = torch.tensor([claim_seq], dtype=torch.long).to(DEVICE)\n",
        "    evid_tensor = torch.tensor([evid_seq], dtype=torch.long).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits = rnn_model(claim_tensor, evid_tensor)\n",
        "        probs = F.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "    return np.array(probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Task 1 on Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": [
        "# ✅\n",
        "word_embedding_path = './word_embedding/evidence_embeddings.npy'\n",
        "word_embedding_meta_path = \"./word_embedding/evidence_meta.pkl\"\n",
        "\n",
        "evidence_embeddings = np.load(word_embedding_path)\n",
        "\n",
        "with open(word_embedding_meta_path, \"rb\") as f:\n",
        "    evidence_ids, evidence_texts, original_evidence_ids = pickle.load(f)\n",
        "\n",
        "arr = np.array(evidence_embeddings, dtype='float32', order='C')\n",
        "\n",
        "dimension = evidence_embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dimension)\n",
        "index.add(np.array(evidence_embeddings, dtype='float32', order='C'))\n",
        "\n",
        "\n",
        "def clean_claim(claim: str) -> str:\n",
        "    claim = claim.lower()\n",
        "    claim = re.sub(r'[^a-z0-9\\s]', '', claim)\n",
        "    claim = re.sub(r'\\s+', ' ', claim).strip()\n",
        "    return claim\n",
        "\n",
        "evidence_dict = dict(zip(evidence_ids, evidence_texts))\n",
        "\n",
        "with open(evidence_path, 'r') as f:\n",
        "    original_evidence_dict = json.load(f)\n",
        "\n",
        "def retrieve_evidence(claim_id, claim_data, retrieval=100, top_k=5):\n",
        "    claim_text = claim_data[\"claim_text\"]\n",
        "    cleaned_claim = clean_claim(claim_text)\n",
        "\n",
        "    claim_embedding = model.encode([cleaned_claim], convert_to_numpy=True, normalize_embeddings=True)\n",
        "    scores, indices = index.search(claim_embedding, retrieval * 3)\n",
        "\n",
        "    seen_original_ids = set()\n",
        "    candidates = []\n",
        "    for i in indices[0]:\n",
        "        eid = evidence_ids[i]\n",
        "        text = evidence_dict[eid]\n",
        "        original_id = original_evidence_ids[i]\n",
        "\n",
        "        if original_id not in seen_original_ids:\n",
        "            candidates.append((original_id, eid, text))\n",
        "            seen_original_ids.add(original_id)\n",
        "\n",
        "        if len(candidates) >= retrieval:\n",
        "            break\n",
        "\n",
        "    pairs = [(claim_text, original_evidence_dict[orig_id]) for (orig_id, _, _) in candidates]  \n",
        "    similarity_scores = reranker.predict(pairs)\n",
        "\n",
        "    reranked = sorted(zip(candidates, similarity_scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    top_k_original_ids = [orig_id for (orig_id, _, _), _ in reranked[:top_k]]\n",
        "\n",
        "    result = {\n",
        "        \"claim_text\": claim_text,\n",
        "        \"evidences\": top_k_original_ids\n",
        "    }\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating R=100, K=3: 100%|██████████| 154/154 [00:21<00:00,  7.14it/s]\n",
            "Retrieval=100, Top-K=3\n",
            "   - Avg Recall   : 22.71%\n",
            "   - Avg Precision: 20.35%\n",
            "   - Avg F1       : 19.85%\n",
            "Evaluating R=100, K=4: 100%|██████████| 154/154 [00:21<00:00,  7.21it/s]\n",
            "Retrieval=100, Top-K=4\n",
            "   - Avg Recall   : 26.36%\n",
            "   - Avg Precision: 18.02%\n",
            "   - Avg F1       : 19.90%\n",
            "Evaluating R=100, K=5: 100%|██████████| 154/154 [00:23<00:00,  6.63it/s]\n",
            "Retrieval=100, Top-K=5\n",
            "   - Avg Recall   : 27.86%\n",
            "   - Avg Precision: 15.45%\n",
            "   - Avg F1       : 18.59%\n",
            "Evaluating R=200, K=3: 100%|██████████| 154/154 [00:38<00:00,  4.03it/s]\n",
            "Retrieval=200, Top-K=3\n",
            "   - Avg Recall   : 22.25%\n",
            "   - Avg Precision: 19.70%\n",
            "   - Avg F1       : 19.32%\n",
            "Evaluating R=200, K=4: 100%|██████████| 154/154 [00:41<00:00,  3.74it/s]\n",
            "Retrieval=200, Top-K=4\n",
            "   - Avg Recall   : 25.65%\n",
            "   - Avg Precision: 17.37%\n",
            "   - Avg F1       : 19.25%\n",
            "Evaluating R=200, K=5: 100%|██████████| 154/154 [00:43<00:00,  3.56it/s]\n",
            "Retrieval=200, Top-K=5\n",
            "   - Avg Recall   : 27.47%\n",
            "   - Avg Precision: 15.06%\n",
            "   - Avg F1       : 18.20%\n",
            "Evaluating R=500, K=3: 100%|██████████| 154/154 [01:45<00:00,  1.46it/s]\n",
            "Retrieval=500, Top-K=3\n",
            "   - Avg Recall   : 20.89%\n",
            "   - Avg Precision: 18.61%\n",
            "   - Avg F1       : 18.25%\n",
            "Evaluating R=500, K=4: 100%|██████████| 154/154 [01:49<00:00,  1.41it/s]\n",
            "Retrieval=500, Top-K=4\n",
            "   - Avg Recall   : 25.31%\n",
            "   - Avg Precision: 16.88%\n",
            "   - Avg F1       : 18.84%\n",
            "Evaluating R=500, K=5: 100%|██████████| 154/154 [01:50<00:00,  1.39it/s]\n",
            "Retrieval=500, Top-K=5\n",
            "   - Avg Recall   : 26.56%\n",
            "   - Avg Precision: 14.55%\n",
            "   - Avg F1       : 17.57%\n",
            "Evaluating R=1000, K=3: 100%|██████████| 154/154 [03:40<00:00,  1.43s/it]\n",
            "Retrieval=1000, Top-K=3\n",
            "   - Avg Recall   : 20.78%\n",
            "   - Avg Precision: 18.61%\n",
            "   - Avg F1       : 18.21%\n",
            "Evaluating R=1000, K=4: 100%|██████████| 154/154 [03:41<00:00,  1.44s/it]\n",
            "Retrieval=1000, Top-K=4\n",
            "   - Avg Recall   : 25.18%\n",
            "   - Avg Precision: 16.72%\n",
            "   - Avg F1       : 18.69%\n",
            "Evaluating R=1000, K=5: 100%|██████████| 154/154 [03:39<00:00,  1.42s/it]\n",
            "Retrieval=1000, Top-K=5\n",
            "   - Avg Recall   : 26.61%\n",
            "   - Avg Precision: 14.55%\n",
            "   - Avg F1       : 17.59%\n",
            "\n",
            "Best Setting: Retrieval=100, Top-K=4, F1=19.90%\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ✅\n",
        "with open(dev_claims_path, 'r') as f:\n",
        "    dev_claims = json.load(f)\n",
        "\n",
        "claim_ids = list(dev_claims.keys())\n",
        "\n",
        "retrieval_values = [100,200,500,1000]\n",
        "top_k_values = [3, 4, 5]\n",
        "\n",
        "best_f1 = 0\n",
        "best_setting = {}\n",
        "\n",
        "for retrieval in retrieval_values:\n",
        "    for top_k in top_k_values:\n",
        "        recalls = []\n",
        "        precisions = []\n",
        "        f1s = []\n",
        "\n",
        "        for cid in tqdm(claim_ids, desc=f\"Evaluating R={retrieval}, K={top_k}\"):\n",
        "            truth = set(dev_claims[cid][\"evidences\"])\n",
        "            \n",
        "            retrieved_info = retrieve_evidence(cid, dev_claims[cid], retrieval=retrieval, top_k=top_k)\n",
        "            retrieved = set(retrieved_info[\"evidences\"])\n",
        "\n",
        "            hit = len(truth & retrieved)\n",
        "\n",
        "            recall = hit / len(truth) if len(truth) > 0 else 0\n",
        "            precision = hit / top_k if top_k > 0 else 0\n",
        "\n",
        "            if precision + recall > 0:\n",
        "                f1 = 2 * precision * recall / (precision + recall)\n",
        "            else:\n",
        "                f1 = 0\n",
        "\n",
        "            recalls.append(recall)\n",
        "            precisions.append(precision)\n",
        "            f1s.append(f1)\n",
        "\n",
        "        avg_recall = np.mean(recalls)\n",
        "        avg_precision = np.mean(precisions)\n",
        "        avg_f1 = np.mean(f1s)\n",
        "\n",
        "        print(f\"\\nRetrieval={retrieval}, Top-K={top_k}\")\n",
        "        print(f\"   - Avg Recall   : {avg_recall:.2%}\")\n",
        "        print(f\"   - Avg Precision: {avg_precision:.2%}\")\n",
        "        print(f\"   - Avg F1       : {avg_f1:.2%}\")\n",
        "\n",
        "        if avg_f1 > best_f1:\n",
        "            best_f1 = avg_f1\n",
        "            best_setting = {'retrieval': retrieval, 'top_k': top_k}\n",
        "\n",
        "print(f\"\\nBest Setting: Retrieval={best_setting['retrieval']}, Top-K={best_setting['top_k']}, F1={best_f1:.2%}\")\n",
        "\n",
        "print(\"\"\"\n",
        "Evaluating R=100, K=3: 100%|██████████| 154/154 [00:21<00:00,  7.14it/s]\n",
        "Retrieval=100, Top-K=3\n",
        "   - Avg Recall   : 22.71%\n",
        "   - Avg Precision: 20.35%\n",
        "   - Avg F1       : 19.85%\n",
        "Evaluating R=100, K=4: 100%|██████████| 154/154 [00:21<00:00,  7.21it/s]\n",
        "Retrieval=100, Top-K=4\n",
        "   - Avg Recall   : 26.36%\n",
        "   - Avg Precision: 18.02%\n",
        "   - Avg F1       : 19.90%\n",
        "Evaluating R=100, K=5: 100%|██████████| 154/154 [00:23<00:00,  6.63it/s]\n",
        "Retrieval=100, Top-K=5\n",
        "   - Avg Recall   : 27.86%\n",
        "   - Avg Precision: 15.45%\n",
        "   - Avg F1       : 18.59%\n",
        "Evaluating R=200, K=3: 100%|██████████| 154/154 [00:38<00:00,  4.03it/s]\n",
        "Retrieval=200, Top-K=3\n",
        "   - Avg Recall   : 22.25%\n",
        "   - Avg Precision: 19.70%\n",
        "   - Avg F1       : 19.32%\n",
        "Evaluating R=200, K=4: 100%|██████████| 154/154 [00:41<00:00,  3.74it/s]\n",
        "Retrieval=200, Top-K=4\n",
        "   - Avg Recall   : 25.65%\n",
        "   - Avg Precision: 17.37%\n",
        "   - Avg F1       : 19.25%\n",
        "Evaluating R=200, K=5: 100%|██████████| 154/154 [00:43<00:00,  3.56it/s]\n",
        "Retrieval=200, Top-K=5\n",
        "   - Avg Recall   : 27.47%\n",
        "   - Avg Precision: 15.06%\n",
        "   - Avg F1       : 18.20%\n",
        "Evaluating R=500, K=3: 100%|██████████| 154/154 [01:45<00:00,  1.46it/s]\n",
        "Retrieval=500, Top-K=3\n",
        "   - Avg Recall   : 20.89%\n",
        "   - Avg Precision: 18.61%\n",
        "   - Avg F1       : 18.25%\n",
        "Evaluating R=500, K=4: 100%|██████████| 154/154 [01:49<00:00,  1.41it/s]\n",
        "Retrieval=500, Top-K=4\n",
        "   - Avg Recall   : 25.31%\n",
        "   - Avg Precision: 16.88%\n",
        "   - Avg F1       : 18.84%\n",
        "Evaluating R=500, K=5: 100%|██████████| 154/154 [01:50<00:00,  1.39it/s]\n",
        "Retrieval=500, Top-K=5\n",
        "   - Avg Recall   : 26.56%\n",
        "   - Avg Precision: 14.55%\n",
        "   - Avg F1       : 17.57%\n",
        "Evaluating R=1000, K=3: 100%|██████████| 154/154 [03:40<00:00,  1.43s/it]\n",
        "Retrieval=1000, Top-K=3\n",
        "   - Avg Recall   : 20.78%\n",
        "   - Avg Precision: 18.61%\n",
        "   - Avg F1       : 18.21%\n",
        "Evaluating R=1000, K=4: 100%|██████████| 154/154 [03:41<00:00,  1.44s/it]\n",
        "Retrieval=1000, Top-K=4\n",
        "   - Avg Recall   : 25.18%\n",
        "   - Avg Precision: 16.72%\n",
        "   - Avg F1       : 18.69%\n",
        "Evaluating R=1000, K=5: 100%|██████████| 154/154 [03:39<00:00,  1.42s/it]\n",
        "Retrieval=1000, Top-K=5\n",
        "   - Avg Recall   : 26.61%\n",
        "   - Avg Precision: 14.55%\n",
        "   - Avg F1       : 17.59%\n",
        "\n",
        "Best Setting: Retrieval=100, Top-K=4, F1=19.90%\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Task 2 on Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ensemble Predicting: 100%|██████████| 154/154 [00:17<00:00,  8.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Ensemble Accuracy on Dev Set: 0.5130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "with open(dev_claims_path, \"r\") as f:\n",
        "    dev_claims = json.load(f)\n",
        "\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for cid, entry in tqdm(dev_claims.items(), desc=\"Ensemble Predicting\"):\n",
        "    claim_text = entry[\"claim_text\"]\n",
        "    evidence_ids = entry.get(\"evidences\", [])\n",
        "    true_label = label2id[entry[\"claim_label\"]]\n",
        "\n",
        "    p1 = get_bert_probs(claim_text, evidence_ids)\n",
        "    p2 = get_bilstm_probs(claim_text, evidence_ids)\n",
        "    p3 = get_rnn_probs(claim_text, evidence_ids)\n",
        "\n",
        "    avg_probs = (p1 + p2 + p3) / 3\n",
        "    pred_idx = int(np.argmax(avg_probs))\n",
        "\n",
        "    true_labels.append(true_label)\n",
        "    pred_labels.append(pred_idx)\n",
        "\n",
        "acc = accuracy_score(true_labels, pred_labels)\n",
        "print(f\"✅ Ensemble Accuracy on Dev Set: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating best model: 100%|██████████| 10/10 [00:03<00:00,  3.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Reloaded Best Model Accuracy: 54.5455%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = BiLSTMWithBertEncoder(\n",
        "    bert_name=BERT_MODEL,\n",
        "    lstm_hid=LSTM_HID_DIM,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    dropout_prob=DROPOUT_PROB,\n",
        "    lstm_layers=NUM_LAYERS,\n",
        ")\n",
        "model.load_state_dict(torch.load(\"task2_best_lstm.pt\", map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "dev_ds = ClaimEvidenceDataset(dev_claims, evidence_dict, tokenizer, MAX_LEN)\n",
        "dev_dl = DataLoader(\n",
        "    dev_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    collate_fn=collate_batch, num_workers=0, pin_memory=True\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "preds, labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input_ids, attn_mask, batch_labels in tqdm(dev_dl, desc=\"Evaluating best model\"):\n",
        "        input_ids = input_ids.to(DEVICE)\n",
        "        attn_mask = attn_mask.to(DEVICE)\n",
        "        batch_labels = batch_labels.to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids, attn_mask)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "\n",
        "        preds.extend(pred.cpu().numpy())\n",
        "        labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(labels, preds)\n",
        "print(f\"🎯 Reloaded Best Model Accuracy: {acc:.4%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nlp_final",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
