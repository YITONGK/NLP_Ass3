{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 0.Environment\n",
        "```bash\n",
        "pip3 install tqdm \n",
        "pip3 install transformers \n",
        "pip install nltk tqdm\n",
        "python -m nltk.downloader punkt stopwords\n",
        "pip install spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          split  # claims avg #evidence                                                         label distribution\n",
            "          train      1228          3.36 {'SUPPORTS': 519, 'NOT_ENOUGH_INFO': 386, 'REFUTES': 199, 'DISPUTED': 124}\n",
            "            dev       154          3.19     {'SUPPORTS': 68, 'NOT_ENOUGH_INFO': 41, 'REFUTES': 27, 'DISPUTED': 18}\n",
            "           test       153             0                                                                         {}\n",
            "evidence-corpus   1208827   19.7 tokens                                                                          -\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import statistics\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_DIR = \"data\"\n",
        "\n",
        "def load_json(fname):\n",
        "    path = os.path.join(DATA_DIR, fname)\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"[WARN] {path} not found, skip.\")\n",
        "        return None\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train     = load_json(\"train-claims.json\")\n",
        "dev       = load_json(\"dev-claims.json\")\n",
        "test      = load_json(\"test-claims-unlabelled.json\")\n",
        "evidence  = load_json(\"evidence.json\")\n",
        "\n",
        "def claim_stats(claim_dict, split_name):\n",
        "    if claim_dict is None:\n",
        "        return {\"split\": split_name, \"n_claims\": 0}\n",
        "\n",
        "    n_claims   = len(claim_dict)\n",
        "    labels     = [v.get(\"claim_label\") for v in claim_dict.values() if \"claim_label\" in v]\n",
        "    ev_per_c   = [len(v.get(\"evidences\", [])) for v in claim_dict.values()]\n",
        "    return {\n",
        "        \"split\": split_name,\n",
        "        \"# claims\": n_claims,\n",
        "        \"avg #evidence\": round(statistics.mean(ev_per_c), 2) if ev_per_c else 0,\n",
        "        \"label distribution\": pd.Series(labels).value_counts().to_dict() if labels else {},\n",
        "    }\n",
        "\n",
        "summary = [\n",
        "    claim_stats(train, \"train\"),\n",
        "    claim_stats(dev,   \"dev\"),\n",
        "    claim_stats(test,  \"test\")\n",
        "]\n",
        "\n",
        "if evidence is not None:\n",
        "    token_lens = [len(passage.split()) for passage in evidence.values()]\n",
        "    summary.append({\n",
        "        \"split\": \"evidence-corpus\",\n",
        "        \"# claims\": len(evidence),     \n",
        "        \"avg #evidence\": f\"{statistics.mean(token_lens):.1f} tokens\",                  \n",
        "        \"label distribution\": \"-\",                               \n",
        "    })\n",
        "\n",
        "print(pd.DataFrame(summary).to_string(index=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No valid cache – preprocessing will start …\n",
            "Tokenising 1,208,827 evidence passages with 9 CPU process(es)…\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stemming evidence: 100%|██████████| 1208827/1208827 [07:30<00:00, 2685.52doc/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evidence saved → /Users/felikskong/Desktop/NLP/NLP_Ass3/preprocessed/evidence_stemmed.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stemming train-claims.json: 100%|██████████| 1228/1228 [00:44<00:00, 27.34doc/s]\n",
            "Stemming dev-claims.json: 100%|██████████| 154/154 [00:44<00:00,  3.45doc/s]\n",
            "Stemming test-claims-unlabelled.json: 100%|██████████| 153/153 [00:44<00:00,  3.44doc/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Claims saved → /Users/felikskong/Desktop/NLP/NLP_Ass3/preprocessed/claims_stemmed.json\n",
            "\n",
            "=== Evidence after stemming ===\n",
            "Total passages        : 1,207,920\n",
            "Stem length (min/max) : 1 / 304\n",
            "Stem length (mean)    : 11.3\n",
            "Vocabulary size       : 510,195\n",
            "Top-20 stems          : [('also', 66963), ('state', 58250), ('bear', 56376), ('first', 53537), ('one', 49589), ('new', 44100), ('year', 42117), ('play', 39752), ('american', 39704), ('includ', 39608), ('use', 39337), ('unit', 38930), ('nation', 37995), ('name', 37335), ('know', 37286), ('district', 34882), ('two', 34481), ('film', 33964), ('counti', 32636), ('footbal', 31480)]\n",
            "\n",
            "Finished in 593.3 s – results cached for future runs.\n"
          ]
        }
      ],
      "source": [
        "# 多进程预处理数据，结果以json文件存在本地\n",
        "\"\"\"\n",
        "Stemming-based preprocessing for the retrieval task.\n",
        "✓ Multi-process spaCy\n",
        "✓ Porter stemming\n",
        "✓ On-disk cache (evidence_stemmed.json / claims_stemmed.json)\n",
        "\"\"\"\n",
        "\n",
        "import json, statistics, collections, time, multiprocessing as mp\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import spacy\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# CONFIGURATION\n",
        "# ------------------------------------------------------------------\n",
        "DATA_DIR      = Path(\"data\")\n",
        "OUT_EVID      = Path(\"preprocessed/evidence_stemmed.json\")\n",
        "OUT_CLAIM     = Path(\"preprocessed/claims_stemmed.json\")\n",
        "FORCE_REBUILD = True                 # True → ignore cache, rebuild\n",
        "BATCH_SIZE    = 1_000                 # spaCy batch size\n",
        "NUM_PROC      = max(mp.cpu_count() - 1, 1)   # use all but 1 core\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# INITIALISE SPACY & STEMMER\n",
        "# ------------------------------------------------------------------\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
        "stemmer = PorterStemmer()\n",
        "stop_set = set(stopwords.words(\"english\"))\n",
        "\n",
        "def stem_doc(doc):\n",
        "    out = []\n",
        "    for tok in doc:\n",
        "        lemma = tok.lemma_.lower()\n",
        "        if lemma.isalpha() and lemma not in stop_set:\n",
        "            out.append(stemmer.stem(lemma))\n",
        "    return out\n",
        "\n",
        "def jload(path: Path):\n",
        "    with path.open(encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def jdump(obj, path: Path):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, ensure_ascii=False)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 0) LOAD CACHE (IF PRESENT)\n",
        "# ------------------------------------------------------------------\n",
        "if OUT_EVID.exists() and OUT_CLAIM.exists() and not FORCE_REBUILD:\n",
        "    t0 = time.time()\n",
        "    evidence_proc  = jload(OUT_EVID)\n",
        "    claim_proc_all = jload(OUT_CLAIM)\n",
        "    print(f\"Cached data loaded in {time.time() - t0:.2f} s – ready to use.\")\n",
        "    exit(0)\n",
        "\n",
        "print(\"No valid cache – preprocessing will start …\")\n",
        "t_start = time.time()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1) PRE-PROCESS EVIDENCE (PARALLEL)\n",
        "# ------------------------------------------------------------------\n",
        "evidence_raw = jload(DATA_DIR / \"evidence.json\")\n",
        "evid_ids     = list(evidence_raw.keys())\n",
        "evid_texts   = list(evidence_raw.values())\n",
        "\n",
        "evidence_proc = {}\n",
        "lengths = []\n",
        "\n",
        "print(f\"Tokenising {len(evid_ids):,} evidence passages \"\n",
        "      f\"with {NUM_PROC} CPU process(es)…\")\n",
        "\n",
        "for evid_id, doc in tqdm(\n",
        "        zip(evid_ids,\n",
        "            nlp.pipe(evid_texts,\n",
        "                     batch_size=BATCH_SIZE,\n",
        "                     n_process=NUM_PROC)),\n",
        "        total=len(evid_ids),\n",
        "        desc=\"Stemming evidence\",\n",
        "        unit=\"doc\"\n",
        "):\n",
        "    stems = stem_doc(doc)\n",
        "    if stems:\n",
        "        evidence_proc[evid_id] = stems\n",
        "        lengths.append(len(stems))\n",
        "\n",
        "jdump(evidence_proc, OUT_EVID)\n",
        "print(f\"Evidence saved → {OUT_EVID.resolve()}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2) PRE-PROCESS CLAIMS (PARALLEL, PER SPLIT)\n",
        "# ------------------------------------------------------------------\n",
        "claim_files = [\n",
        "    \"train-claims.json\",\n",
        "    \"dev-claims.json\",\n",
        "    \"test-claims-unlabelled.json\",\n",
        "]\n",
        "claim_proc_all = {}\n",
        "\n",
        "for fname in claim_files:\n",
        "    raw_claims = jload(DATA_DIR / fname)\n",
        "    cids  = list(raw_claims.keys())\n",
        "    texts = [raw_claims[cid][\"claim_text\"] for cid in cids]\n",
        "\n",
        "    for cid, doc in tqdm(\n",
        "            zip(cids,\n",
        "                nlp.pipe(texts,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         n_process=NUM_PROC)),\n",
        "            total=len(cids),\n",
        "            desc=f\"Stemming {fname}\",\n",
        "            unit=\"doc\"\n",
        "    ):\n",
        "        stems = stem_doc(doc)\n",
        "        if stems:\n",
        "            claim_proc_all[cid] = stems\n",
        "\n",
        "jdump(claim_proc_all, OUT_CLAIM)\n",
        "print(f\"Claims saved → {OUT_CLAIM.resolve()}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3) QUICK CORPUS STATISTICS\n",
        "# ------------------------------------------------------------------\n",
        "print(\"\\n=== Evidence after stemming ===\")\n",
        "print(f\"Total passages        : {len(evidence_proc):,}\")\n",
        "print(f\"Stem length (min/max) : {min(lengths)} / {max(lengths)}\")\n",
        "print(f\"Stem length (mean)    : {statistics.mean(lengths):.1f}\")\n",
        "\n",
        "vocab = {s for toks in evidence_proc.values() for s in toks}\n",
        "print(f\"Vocabulary size       : {len(vocab):,}\")\n",
        "\n",
        "counter = collections.Counter(s for toks in evidence_proc.values() for s in toks)\n",
        "print(\"Top-20 stems          :\", counter.most_common(20))\n",
        "\n",
        "print(f\"\\nFinished in {time.time() - t_start:.1f} s – \"\n",
        "      f\"results cached for future runs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[train] total samples: 8242 (1228 claims)\n",
            "[dev] total samples: 982 (154 claims)\n"
          ]
        }
      ],
      "source": [
        "import json, random, math, time, itertools, collections\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_DIR   = Path(\"data\")\n",
        "STEM_EVID  = Path(\"preprocessed/evidence_stemmed.json\")\n",
        "STEM_CLAIM = Path(\"preprocessed/claims_stemmed.json\")\n",
        "\n",
        "# 加载数据\n",
        "claim_tokens = json.loads(STEM_CLAIM.read_text())\n",
        "evidence_tokens = json.loads(STEM_EVID.read_text())\n",
        "\n",
        "train_lbl = json.loads((DATA_DIR / \"train-claims.json\").read_text())\n",
        "dev_lbl   = json.loads((DATA_DIR / \"dev-claims.json\").read_text())\n",
        "\n",
        "# 所有 evidence ID（用于采样负例）\n",
        "all_evid_ids = list(evidence_tokens.keys())\n",
        "\n",
        "# helper：构建正负样本\n",
        "def build_dataset(claim_label_dict, mode=\"train\", neg_ratio=1):\n",
        "    dataset = []\n",
        "    for cid, info in claim_label_dict.items():\n",
        "        claim_tok = claim_tokens.get(cid)\n",
        "        if not claim_tok:\n",
        "            continue\n",
        "\n",
        "        pos_evids = [eid for eid in info.get(\"evidences\", []) if eid in evidence_tokens]\n",
        "        for eid in pos_evids:\n",
        "            dataset.append({\n",
        "                \"claim_id\": cid,\n",
        "                \"evidence_id\": eid,\n",
        "                \"claim_tokens\": claim_tok,\n",
        "                \"evidence_tokens\": evidence_tokens[eid],\n",
        "                \"label\": 1\n",
        "            })\n",
        "\n",
        "        # 构造负例（从非相关的 evidence 中随机采样）\n",
        "        if neg_ratio > 0:\n",
        "            for _ in range(len(pos_evids) * neg_ratio):\n",
        "                while True:\n",
        "                    neg_eid = random.choice(all_evid_ids)\n",
        "                    if neg_eid not in pos_evids and neg_eid in evidence_tokens:\n",
        "                        dataset.append({\n",
        "                            \"claim_id\": cid,\n",
        "                            \"evidence_id\": neg_eid,\n",
        "                            \"claim_tokens\": claim_tok,\n",
        "                            \"evidence_tokens\": evidence_tokens[neg_eid],\n",
        "                            \"label\": 0\n",
        "                        })\n",
        "                        break\n",
        "    print(f\"[{mode}] total samples: {len(dataset)} ({len(claim_label_dict)} claims)\")\n",
        "    return dataset\n",
        "\n",
        "train_data = build_dataset(train_lbl, mode=\"train\", neg_ratio=1)\n",
        "dev_data   = build_dataset(dev_lbl, mode=\"dev\", neg_ratio=1)\n",
        "\n",
        "Path(\"cached\").mkdir(exist_ok=True)\n",
        "with open(\"cached/train_retrieval.json\", \"w\") as f:\n",
        "    json.dump(train_data, f, ensure_ascii=False)\n",
        "with open(\"cached/dev_retrieval.json\", \"w\") as f:\n",
        "    json.dump(dev_data, f, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "def build_vocab(data_list, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for item in data_list:\n",
        "        counter.update(item[\"claim_tokens\"])\n",
        "        counter.update(item[\"evidence_tokens\"])\n",
        "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[token] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, data, vocab, max_len=100):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def encode(self, tokens):\n",
        "        ids = [self.vocab.get(tok, self.vocab[\"<UNK>\"]) for tok in tokens]\n",
        "        if len(ids) > self.max_len:\n",
        "            return ids[:self.max_len]\n",
        "        return ids + [self.vocab[\"<PAD>\"]] * (self.max_len - len(ids))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        claim_ids = self.encode(item[\"claim_tokens\"])\n",
        "        evid_ids = self.encode(item[\"evidence_tokens\"])\n",
        "        label = torch.tensor(item[\"label\"], dtype=torch.float)\n",
        "        return torch.tensor(claim_ids), torch.tensor(evid_ids), label\n",
        "    \n",
        "import torch.nn as nn\n",
        "\n",
        "class SiameseLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * 4, 1)  # concat [c_avg, e_avg]\n",
        "    \n",
        "    def encode(self, x):\n",
        "        embedded = self.embedding(x)  # (B, T, E)\n",
        "        outputs, _ = self.lstm(embedded)  # (B, T, 2H)\n",
        "        avg = outputs.mean(dim=1)  # average pooling\n",
        "        return avg  # (B, 2H)\n",
        "\n",
        "    def forward(self, claim, evid):\n",
        "        c_repr = self.encode(claim)\n",
        "        e_repr = self.encode(evid)\n",
        "        x = torch.cat([c_repr, e_repr], dim=1)\n",
        "        logits = self.fc(x).squeeze(1)  # (B,)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.4656 | acc: 0.7923 | auc: 0.8713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dev  loss: 0.3707 | acc: 0.8585 | auc: 0.9389\n",
            "✅ Best model saved with dev AUC: 0.9389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import json, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# Load and preprocess data\n",
        "# -----------------------------\n",
        "train_data = json.load(open(\"cached/train_retrieval.json\"))\n",
        "dev_data   = json.load(open(\"cached/dev_retrieval.json\"))\n",
        "\n",
        "def build_vocab(data_list, min_freq=2):\n",
        "    counter = Counter()\n",
        "    for item in data_list:\n",
        "        counter.update(item[\"claim_tokens\"])\n",
        "        counter.update(item[\"evidence_tokens\"])\n",
        "    vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "    for token, freq in counter.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[token] = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab(train_data + dev_data)\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, data, vocab, max_len=100):\n",
        "        self.data = data\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def encode(self, tokens):\n",
        "        ids = [self.vocab.get(tok, self.vocab[\"<UNK>\"]) for tok in tokens]\n",
        "        if len(ids) > self.max_len:\n",
        "            return ids[:self.max_len]\n",
        "        return ids + [self.vocab[\"<PAD>\"]] * (self.max_len - len(ids))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        claim_ids = self.encode(item[\"claim_tokens\"])\n",
        "        evid_ids  = self.encode(item[\"evidence_tokens\"])\n",
        "        label = torch.tensor(item[\"label\"], dtype=torch.float)\n",
        "        return torch.tensor(claim_ids), torch.tensor(evid_ids), label\n",
        "\n",
        "train_dataset = ClaimEvidenceDataset(train_data, vocab)\n",
        "dev_dataset   = ClaimEvidenceDataset(dev_data, vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "dev_loader   = DataLoader(dev_dataset, batch_size=64)\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class SiameseLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * 4, 1)\n",
        "    \n",
        "    def encode(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, _ = self.lstm(embedded)\n",
        "        avg = outputs.mean(dim=1)\n",
        "        return avg\n",
        "\n",
        "    def forward(self, claim, evid):\n",
        "        c_repr = self.encode(claim)\n",
        "        e_repr = self.encode(evid)\n",
        "        x = torch.cat([c_repr, e_repr], dim=1)\n",
        "        logits = self.fc(x).squeeze(1)\n",
        "        return logits\n",
        "\n",
        "# -----------------------------\n",
        "# Train & Eval Functions\n",
        "# -----------------------------\n",
        "def train_one_epoch(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for claim, evid, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        claim, evid, label = claim.to(device), evid.to(device), label.to(device)\n",
        "        logits = model(claim, evid)\n",
        "        loss = F.binary_cross_entropy_with_logits(logits, label)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        all_preds.extend(torch.sigmoid(logits).detach().cpu().numpy())\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "    preds_binary = [1 if p > 0.5 else 0 for p in all_preds]\n",
        "    acc = accuracy_score(all_labels, preds_binary)\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    return total_loss / len(dataloader), acc, auc\n",
        "\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for claim, evid, label in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            claim, evid, label = claim.to(device), evid.to(device), label.to(device)\n",
        "            logits = model(claim, evid)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, label)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            all_preds.extend(torch.sigmoid(logits).cpu().numpy())\n",
        "            all_labels.extend(label.cpu().numpy())\n",
        "\n",
        "    preds_binary = [1 if p > 0.5 else 0 for p in all_preds]\n",
        "    acc = accuracy_score(all_labels, preds_binary)\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    return total_loss / len(dataloader), acc, auc\n",
        "\n",
        "# -----------------------------\n",
        "# Training Loop\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SiameseLSTM(vocab_size=len(vocab)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "best_auc = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
        "    train_loss, train_acc, train_auc = train_one_epoch(model, train_loader, optimizer, device)\n",
        "    print(f\"Train loss: {train_loss:.4f} | acc: {train_acc:.4f} | auc: {train_auc:.4f}\")\n",
        "\n",
        "    dev_loss, dev_acc, dev_auc = evaluate(model, dev_loader, device)\n",
        "    print(f\" Dev  loss: {dev_loss:.4f} | acc: {dev_acc:.4f} | auc: {dev_auc:.4f}\")\n",
        "\n",
        "    # 保存最佳模型\n",
        "    if dev_auc > best_auc:\n",
        "        best_auc = dev_auc\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(f\"✅ Best model saved with dev AUC: {best_auc:.4f}\")\n",
        "\n",
        "with open(\"cached/vocab.json\", \"w\") as f:\n",
        "    json.dump(vocab, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xv/d8fp_fgs1fx30rm4fs63qv1c0000gn/T/ipykernel_64641/679436665.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_model.pt\", map_location=device))\n",
            "Evaluating:   0%|          | 0/154 [40:50<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     94\u001b[39m truth = \u001b[38;5;28mset\u001b[39m(dev_claims[cid][\u001b[33m\"\u001b[39m\u001b[33mevidences\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     95\u001b[39m claim_text = dev_claims[cid][\u001b[33m\"\u001b[39m\u001b[33mclaim_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m retrieved = [eid \u001b[38;5;28;01mfor\u001b[39;00m eid, _ \u001b[38;5;129;01min\u001b[39;00m retrieve_evidence(claim_text, top_k)]\n\u001b[32m     98\u001b[39m hit = \u001b[38;5;28mlen\u001b[39m(truth & \u001b[38;5;28mset\u001b[39m(retrieved))\n\u001b[32m     99\u001b[39m recall = hit / \u001b[38;5;28mlen\u001b[39m(truth) \u001b[38;5;28;01mif\u001b[39;00m truth \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mretrieve_evidence\u001b[39m\u001b[34m(claim_text, top_k, batch_size, max_len)\u001b[39m\n\u001b[32m     76\u001b[39m e_tensor = torch.tensor(batch_e).to(device)\n\u001b[32m     77\u001b[39m c_batch = c_tensor.repeat(e_tensor.size(\u001b[32m0\u001b[39m), \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m logits = model(c_batch, e_tensor)\n\u001b[32m     80\u001b[39m probs = torch.sigmoid(logits).cpu().numpy()\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, score \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(probs):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mSiameseLSTM.forward\u001b[39m\u001b[34m(self, claim, evid)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, claim, evid):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     c = \u001b[38;5;28mself\u001b[39m.encode(claim)\n\u001b[32m     45\u001b[39m     e = \u001b[38;5;28mself\u001b[39m.encode(evid)\n\u001b[32m     46\u001b[39m     x = torch.cat([c, e], dim=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mSiameseLSTM.encode\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     39\u001b[39m     emb = \u001b[38;5;28mself\u001b[39m.embedding(x)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     out, _ = \u001b[38;5;28mself\u001b[39m.lstm(emb)\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out.mean(dim=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1123\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1120\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1123\u001b[39m     result = _VF.lstm(\n\u001b[32m   1124\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1125\u001b[39m         hx,\n\u001b[32m   1126\u001b[39m         \u001b[38;5;28mself\u001b[39m._flat_weights,\n\u001b[32m   1127\u001b[39m         \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m   1128\u001b[39m         \u001b[38;5;28mself\u001b[39m.num_layers,\n\u001b[32m   1129\u001b[39m         \u001b[38;5;28mself\u001b[39m.dropout,\n\u001b[32m   1130\u001b[39m         \u001b[38;5;28mself\u001b[39m.training,\n\u001b[32m   1131\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1132\u001b[39m         \u001b[38;5;28mself\u001b[39m.batch_first,\n\u001b[32m   1133\u001b[39m     )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     result = _VF.lstm(\n\u001b[32m   1136\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1137\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1145\u001b[39m     )\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# -----------------------------\n",
        "# Load data\n",
        "# -----------------------------\n",
        "with open(\"preprocessed/evidence_stemmed.json\") as f:\n",
        "    evidence_db = json.load(f)\n",
        "with open(\"preprocessed/claims_stemmed.json\") as f:\n",
        "    claim_tokens = json.load(f)\n",
        "with open(\"data/dev-claims.json\") as f:\n",
        "    dev_claims = json.load(f)\n",
        "with open(\"cached/vocab.json\") as f:\n",
        "    vocab = json.load(f)\n",
        "vocab = {k: int(v) for k, v in vocab.items()}\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def encode_tokens(tokens, vocab, max_len=100):\n",
        "    ids = [vocab.get(tok, vocab[\"<UNK>\"]) for tok in tokens]\n",
        "    return ids[:max_len] + [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class SiameseLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * 4, 1)\n",
        "\n",
        "    def encode(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        out, _ = self.lstm(emb)\n",
        "        return out.mean(dim=1)\n",
        "\n",
        "    def forward(self, claim, evid):\n",
        "        c = self.encode(claim)\n",
        "        e = self.encode(evid)\n",
        "        x = torch.cat([c, e], dim=1)\n",
        "        return self.fc(x).squeeze(1)\n",
        "\n",
        "# -----------------------------\n",
        "# Load model\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SiameseLSTM(len(vocab)).to(device)\n",
        "model.load_state_dict(torch.load(\"best_model.pt\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# -----------------------------\n",
        "# Retrieval function (batched)\n",
        "# -----------------------------\n",
        "def retrieve_evidence(claim_text, top_k=5, batch_size=512, max_len=100):\n",
        "    with torch.no_grad():\n",
        "        cid = next((k for k, v in dev_claims.items() if v[\"claim_text\"] == claim_text), None)\n",
        "        if cid is None or cid not in claim_tokens:\n",
        "            return []\n",
        "\n",
        "        c_tok = claim_tokens[cid]\n",
        "        c_enc = encode_tokens(c_tok, vocab, max_len)\n",
        "        c_tensor = torch.tensor(c_enc).unsqueeze(0).to(device)\n",
        "\n",
        "        evidence_ids = list(evidence_db.keys())\n",
        "        evidence_encs = [encode_tokens(evidence_db[eid], vocab, max_len) for eid in evidence_ids]\n",
        "\n",
        "        scores = []\n",
        "        for i in range(0, len(evidence_encs), batch_size):\n",
        "            batch_e = evidence_encs[i:i+batch_size]\n",
        "            e_tensor = torch.tensor(batch_e).to(device)\n",
        "            c_batch = c_tensor.repeat(e_tensor.size(0), 1)\n",
        "\n",
        "            logits = model(c_batch, e_tensor)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "            for j, score in enumerate(probs):\n",
        "                scores.append((evidence_ids[i + j], score))\n",
        "\n",
        "        return sorted(scores, key=lambda x: x[1], reverse=True)[:top_k]\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate on dev set\n",
        "# -----------------------------\n",
        "top_k = 5\n",
        "recalls, precisions, f1s = [], [], []\n",
        "\n",
        "for cid in tqdm(dev_claims, desc=\"Evaluating\"):\n",
        "    truth = set(dev_claims[cid][\"evidences\"])\n",
        "    claim_text = dev_claims[cid][\"claim_text\"]\n",
        "    retrieved = [eid for eid, _ in retrieve_evidence(claim_text, top_k)]\n",
        "\n",
        "    hit = len(truth & set(retrieved))\n",
        "    recall = hit / len(truth) if truth else 0\n",
        "    precision = hit / top_k\n",
        "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
        "\n",
        "    recalls.append(recall)\n",
        "    precisions.append(precision)\n",
        "    f1s.append(f1)\n",
        "\n",
        "# -----------------------------\n",
        "# Print results\n",
        "# -----------------------------\n",
        "print(f\"\\nAverage Recall@{top_k}:    {np.mean(recalls):.2%}\")\n",
        "print(f\"Average Precision@{top_k}: {np.mean(precisions):.2%}\")\n",
        "print(f\"Average F1@{top_k}:        {np.mean(f1s):.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
