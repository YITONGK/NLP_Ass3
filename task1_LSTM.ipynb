{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c25060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports & Config\n",
    "import os, json, random, itertools, collections\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Hyperparameters & Paths\n",
    "DATA_DIR      = Path(\"data\")\n",
    "PRE_DIR       = Path(\"preprocessed\")\n",
    "EVID_J        = PRE_DIR/\"evidence_stemmed.json\"\n",
    "CLAIM_J       = PRE_DIR/\"claims_stemmed.json\"\n",
    "TRAIN_J       = DATA_DIR/\"train-claims.json\"\n",
    "DEV_J         = DATA_DIR/\"dev-claims.json\"\n",
    "EVID_CORPUS_J = DATA_DIR/\"evidence.json\"\n",
    "\n",
    "EMB_DIM   = 100\n",
    "HID_DIM   = 128\n",
    "BATCH     = 128\n",
    "EPOCHS    = 5\n",
    "LR        = 3e-4\n",
    "MARGIN    = 0.3\n",
    "MIN_FREQ  = 3\n",
    "TOP_K     = 5\n",
    "DEVICE    = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1) Load pre-stemmed data\n",
    "with open(EVID_J, \"r\", encoding=\"utf-8\") as f:\n",
    "    evidence_proc = json.load(f)\n",
    "with open(CLAIM_J, \"r\", encoding=\"utf-8\") as f:\n",
    "    claim_proc_all = json.load(f)\n",
    "\n",
    "# 2) Build vocab\n",
    "freq = collections.Counter(\n",
    "    t for toks in itertools.chain(evidence_proc.values(),\n",
    "                                  claim_proc_all.values())\n",
    "    for t in toks\n",
    ")\n",
    "PAD, UNK = \"<PAD>\", \"<UNK>\"\n",
    "itos = [PAD, UNK] + [t for t,c in freq.items() if c>=MIN_FREQ]\n",
    "stoi = {t:i for i,t in enumerate(itos)}\n",
    "def numerise(tokens):\n",
    "    return [stoi.get(t, stoi[UNK]) for t in tokens]\n",
    "\n",
    "# 3) Load labels\n",
    "train_lbl = json.loads(TRAIN_J.read_text())\n",
    "dev_lbl   = json.loads(DEV_J.read_text())\n",
    "\n",
    "# 4) Triplet Dataset & DataLoader\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, labeled, evid_dict):\n",
    "        items, evid_ids = [], list(evid_dict.keys())\n",
    "        for cid, obj in labeled.items():\n",
    "            pos = [e for e in obj[\"evidences\"] if e in evid_dict]\n",
    "            for p in pos:\n",
    "                n = random.choice(evid_ids)\n",
    "                while n==p: n = random.choice(evid_ids)\n",
    "                items.append((cid, p, n))\n",
    "        self.items = items\n",
    "        self.evid  = evid_dict\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    def __getitem__(self, idx):\n",
    "        cid,p,n = self.items[idx]\n",
    "        return (\n",
    "          torch.tensor(numerise(claim_proc_all[cid]), dtype=torch.long),\n",
    "          torch.tensor(numerise(self.evid[p]), dtype=torch.long),\n",
    "          torch.tensor(numerise(self.evid[n]), dtype=torch.long),\n",
    "        )\n",
    "\n",
    "def collate_fn(batch):\n",
    "    def pad(seqs):\n",
    "        m = max(len(s) for s in seqs)\n",
    "        return torch.tensor([s.tolist()+[0]*(m-len(s)) for s in seqs])\n",
    "    c,p,n = zip(*batch)\n",
    "    return pad(c), pad(p), pad(n)\n",
    "\n",
    "train_ds = TripletDataset(train_lbl, evidence_proc)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,\n",
    "                      collate_fn=collate_fn)\n",
    "\n",
    "# 5) BiLSTM Sentence Encoder\n",
    "class BiLSTMSentenceEncoder(nn.Module):\n",
    "    def __init__(self, vocab_sz, emb_dim=EMB_DIM, hid_dim=HID_DIM):\n",
    "        super().__init__()\n",
    "        self.emb  = nn.Embedding(vocab_sz, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True,\n",
    "                            bidirectional=True)\n",
    "    def forward(self, x):\n",
    "        mask = (x!=0).float().unsqueeze(-1)\n",
    "        out, _ = self.lstm(self.emb(x))\n",
    "        # mean‐pool over the length dim\n",
    "        out = (out * mask).sum(1) / mask.sum(1)\n",
    "        return nn.functional.normalize(out, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd514b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 33/33 [01:40<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1 avg loss = 0.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 33/33 [01:59<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2 avg loss = 0.0652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 33/33 [01:42<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3 avg loss = 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 33/33 [01:37<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4 avg loss = 0.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 33/33 [01:37<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5 avg loss = 0.0240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6) Train the retriever\n",
    "model   = BiLSTMSentenceEncoder(len(itos)).to(DEVICE)\n",
    "optim   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MarginRankingLoss(margin=MARGIN)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for c, p, n in tqdm(train_dl, desc=f\"Epoch {epoch+1}\"):\n",
    "        c,p,n = [t.to(DEVICE) for t in (c,p,n)]\n",
    "        vc, vp, vn = model(c), model(p), model(n)\n",
    "        pos_sim = (vc * vp).sum(1)\n",
    "        neg_sim = (vc * vn).sum(1)\n",
    "        loss    = loss_fn(pos_sim, neg_sim,\n",
    "                          torch.ones_like(pos_sim, device=DEVICE))\n",
    "        optim.zero_grad(); loss.backward(); optim.step()\n",
    "        total += loss.item()\n",
    "    print(f\"  Epoch {epoch+1} avg loss = {total/len(train_dl):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d1949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding evidence: 100%|██████████| 2360/2360 [54:32<00:00,  1.39s/it] \n"
     ]
    }
   ],
   "source": [
    "# 7) Encode all evidence\n",
    "# single‐worker to avoid multiprocessing issues in notebook\n",
    "evidence_vecs = {}\n",
    "loader = DataLoader(\n",
    "    [(eid, torch.tensor(numerise(evidence_proc[eid]),\n",
    "                        dtype=torch.long))\n",
    "     for eid in evidence_proc],\n",
    "    batch_size=512, shuffle=False,\n",
    "    collate_fn=lambda batch: (\n",
    "        [e[0] for e in batch],\n",
    "        pad_sequence([e[1] for e in batch],\n",
    "                     batch_first=True, padding_value=0)\n",
    "    ),\n",
    "    num_workers=0,\n",
    ")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for eids, seqs in tqdm(loader, desc=\"Encoding evidence\"):\n",
    "        vecs = model(seqs.to(DEVICE)).cpu()\n",
    "        for eid, v in zip(eids, vecs):\n",
    "            evidence_vecs[eid] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8739abb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 154/154 [04:50<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall@3:    5.01%\n",
      "Precision@3: 3.90%\n",
      "F1@3:        4.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 154/154 [04:44<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall@4:    5.90%\n",
      "Precision@4: 3.57%\n",
      "F1@4:        4.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 154/154 [04:49<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall@5:    6.24%\n",
      "Precision@5: 3.12%\n",
      "F1@5:        3.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 8) Ranking & Evaluation on dev\n",
    "def rank_evidence(stems, top_k):\n",
    "    idxs = numerise(stems)\n",
    "    x = torch.tensor([idxs], dtype=torch.long, device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        vc = model(x).cpu().squeeze(0)\n",
    "    sims = {eid: float(torch.dot(vc, v_e))\n",
    "            for eid, v_e in evidence_vecs.items()}\n",
    "    return sorted(sims, key=sims.get, reverse=True)[:top_k]\n",
    "\n",
    "def evaluate(top_k):\n",
    "    recalls, precisions, f1s = [], [], []\n",
    "    for cid, obj in tqdm(dev_lbl.items(), desc=\"Evaluating\"):\n",
    "        gold      = set(obj[\"evidences\"])\n",
    "        retrieved = rank_evidence(claim_proc_all[cid], top_k)\n",
    "        hits      = len(gold & set(retrieved))\n",
    "        r = hits/len(gold) if gold else 0.0\n",
    "        p = hits/top_k\n",
    "        f = (2*r*p/(r+p)) if (r+p)>0 else 0.0\n",
    "        recalls.append(r); precisions.append(p); f1s.append(f)\n",
    "\n",
    "    print(f\"\\nRecall@{top_k}:    {np.mean(recalls):.2%}\")\n",
    "    print(f\"Precision@{top_k}: {np.mean(precisions):.2%}\")\n",
    "    print(f\"F1@{top_k}:        {np.mean(f1s):.2%}\")\n",
    "\n",
    "for k in [3, 4, 5]:\n",
    "    evaluate(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
