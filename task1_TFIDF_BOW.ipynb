{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/felikskong/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/felikskong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          split  # claims avg #evidence                                                         label distribution\n",
      "          train      1228          3.36 {'SUPPORTS': 519, 'NOT_ENOUGH_INFO': 386, 'REFUTES': 199, 'DISPUTED': 124}\n",
      "            dev       154          3.19     {'SUPPORTS': 68, 'NOT_ENOUGH_INFO': 41, 'REFUTES': 27, 'DISPUTED': 18}\n",
      "           test       153             0                                                                         {}\n",
      "evidence-corpus   1208827   19.7 tokens                                                                          -\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"data\"\n",
    "\n",
    "def load_json(fname):\n",
    "    path = os.path.join(DATA_DIR, fname)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[WARN] {path} not found, skip.\")\n",
    "        return None\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_claims    = load_json(\"train-claims.json\")\n",
    "dev_claims      = load_json(\"dev-claims.json\")\n",
    "test_claims     = load_json(\"test-claims-unlabelled.json\")\n",
    "evidence        = load_json(\"evidence.json\")\n",
    "\n",
    "def claim_stats(claim_dict, split_name):\n",
    "    if claim_dict is None:\n",
    "        return {\"split\": split_name, \"n_claims\": 0}\n",
    "\n",
    "    n_claims   = len(claim_dict)\n",
    "    labels     = [v.get(\"claim_label\") for v in claim_dict.values() if \"claim_label\" in v]\n",
    "    ev_per_c   = [len(v.get(\"evidences\", [])) for v in claim_dict.values()]\n",
    "    return {\n",
    "        \"split\": split_name,\n",
    "        \"# claims\": n_claims,\n",
    "        \"avg #evidence\": round(statistics.mean(ev_per_c), 2) if ev_per_c else 0,\n",
    "        \"label distribution\": pd.Series(labels).value_counts().to_dict() if labels else {},\n",
    "    }\n",
    "\n",
    "summary = [\n",
    "    claim_stats(train_claims, \"train\"),\n",
    "    claim_stats(dev_claims,   \"dev\"),\n",
    "    claim_stats(test_claims,  \"test\")\n",
    "]\n",
    "\n",
    "if evidence is not None:\n",
    "    token_lens = [len(passage.split()) for passage in evidence.values()]\n",
    "    summary.append({\n",
    "        \"split\": \"evidence-corpus\",\n",
    "        \"# claims\": len(evidence),     \n",
    "        \"avg #evidence\": f\"{statistics.mean(token_lens):.1f} tokens\",                  \n",
    "        \"label distribution\": \"-\",                               \n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(summary).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word, \"v\")\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word, \"n\")\n",
    "    return lemma\n",
    "\n",
    "def is_keep_token(tok: str) -> bool:\n",
    "    return (\n",
    "        tok.isascii()\n",
    "        and\n",
    "        tok.lower() not in stop_words\n",
    "    )\n",
    "\n",
    "\n",
    "def text_tokenizer(text: str) -> list[str]:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    cleaned: list[str] = []\n",
    "    for tok in tokens:\n",
    "        if not is_keep_token(tok):\n",
    "            continue\n",
    "\n",
    "        cleaned.append(lemmatize(tok) if tok.isalpha() else tok)\n",
    "    if len(cleaned) < 5:\n",
    "        return []\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIEqDDT78q39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felikskong/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evidence_ids = list(evidence.keys())\n",
    "evidence_text_list = [evidence[eid] for eid in evidence_ids]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, tokenizer=text_tokenizer)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(evidence_text_list)\n",
    "\n",
    "bow_vectorizer = CountVectorizer(max_features=5000, tokenizer=text_tokenizer)\n",
    "bow_vectors = bow_vectorizer.fit_transform(evidence_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_claims_ids = list(dev_claims.keys())\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "dev_claims_vectors = tfidf_vectorizer.transform([dev_claims[claim_id]['claim_text'] for claim_id in dev_claims_ids])\n",
    "tfidf_cosine_similarities = cosine_similarity(dev_claims_vectors, tfidf_vectors)\n",
    "\n",
    "top_k_evidence_tfidf = {\n",
    "    claim_id: np.argsort(-tfidf_cosine_similarities[i])[:top_k].tolist()\n",
    "    for i, claim_id in enumerate(dev_claims_ids)\n",
    "}\n",
    "\n",
    "dev_claims_retrieved_tfidf = {\n",
    "    claim_id: {\n",
    "        \"claim_text\": dev_claims[claim_id]['claim_text'],\n",
    "        \"claim_label\": dev_claims[claim_id]['claim_label'],\n",
    "        \"evidences\": [evidence_ids[i] for i in top_k_evidence_tfidf[claim_id]],\n",
    "    }\n",
    "    for claim_id in dev_claims_ids\n",
    "}\n",
    "\n",
    "dev_claims_bow_vectors = bow_vectorizer.transform([dev_claims[claim_id]['claim_text'] for claim_id in dev_claims_ids])\n",
    "bow_cosine_similarities = cosine_similarity(dev_claims_bow_vectors, bow_vectors)\n",
    "\n",
    "top_k_evidence_bow = {\n",
    "    claim_id: np.argsort(-bow_cosine_similarities[i])[:top_k].tolist()\n",
    "    for i, claim_id in enumerate(dev_claims_ids)\n",
    "}\n",
    "\n",
    "dev_claims_retrieved_bow = {\n",
    "    claim_id: {\n",
    "        \"claim_text\": dev_claims[claim_id]['claim_text'],\n",
    "        \"claim_label\": dev_claims[claim_id]['claim_label'],\n",
    "        \"evidences\": [evidence_ids[i] for i in top_k_evidence_bow[claim_id]],\n",
    "    }\n",
    "    for claim_id in dev_claims_ids\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF  →  Precision: 0.0866  |  Recall: 0.0951  |  F1: 0.0836\n",
      "BoW     →  Precision: 0.0606  |  Recall: 0.0765  |  F1: 0.0613\n"
     ]
    }
   ],
   "source": [
    "def evaluate(retrieved_dict: dict[str, dict]) -> tuple[float, float, float]:\n",
    "    precisions, recalls, f1s = [], [], []\n",
    "\n",
    "    for cid, claim in dev_claims.items():\n",
    "        pred   = set(retrieved_dict[cid][\"evidences\"])\n",
    "        truth  = set(claim[\"evidences\"])\n",
    "        correct = len(pred & truth)\n",
    "\n",
    "        if correct:\n",
    "            prec = correct / len(pred)\n",
    "            rec  = correct / len(truth)\n",
    "            f1   = 2 * prec * rec / (prec + rec)\n",
    "        else:\n",
    "            prec = rec = f1 = 0.0\n",
    "\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls), np.mean(f1s)\n",
    "\n",
    "systems = [\n",
    "    (\"TF-IDF\", dev_claims_retrieved_tfidf),\n",
    "    (\"BoW\",    dev_claims_retrieved_bow),\n",
    "]\n",
    "\n",
    "for name, retrieved in systems:\n",
    "    p, r, f = evaluate(retrieved)\n",
    "    print(f\"{name:<7} →  Precision: {p:.4f}  |  Recall: {r:.4f}  |  F1: {f:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test claims with retrieved evidences saved to data/test_claims_retrieved_tfidf.json.\n",
      "Test claims with retrieved evidences saved to data/test_claims_retrieved_bow.json.\n"
     ]
    }
   ],
   "source": [
    "test_claims_ids = list(test_claims.keys())\n",
    "test_claims_vectors = tfidf_vectorizer.transform([test_claims[claim_id]['claim_text'] for claim_id in test_claims_ids])\n",
    "test_cosine_similarities = cosine_similarity(test_claims_vectors, tfidf_vectors)\n",
    "\n",
    "top_k_evidence_test_tfidf = {\n",
    "    claim_id: np.argsort(-test_cosine_similarities[i])[:top_k].tolist()\n",
    "    for i, claim_id in enumerate(test_claims_ids)\n",
    "}\n",
    "\n",
    "test_claims_retrieved_tfidf = {\n",
    "    claim_id: {\n",
    "        \"claim_text\": test_claims[claim_id]['claim_text'],\n",
    "        \"evidences\": [evidence_ids[i] for i in top_k_evidence_test_tfidf[claim_id]],\n",
    "    }\n",
    "    for claim_id in test_claims_ids\n",
    "}\n",
    "\n",
    "output_file = os.path.join(DATA_DIR, \"test_claims_retrieved_tfidf.json\")\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(test_claims_retrieved_tfidf, f, indent=4)\n",
    "\n",
    "print(f\"Test claims with retrieved evidences saved to {output_file}.\")\n",
    "\n",
    "test_claims_vectors_bow = bow_vectorizer.transform([test_claims[claim_id]['claim_text'] for claim_id in test_claims_ids])\n",
    "test_cosine_similarities_bow = cosine_similarity(test_claims_vectors_bow, bow_vectors)\n",
    "\n",
    "top_k_evidence_test_bow = {\n",
    "    claim_id: np.argsort(-test_cosine_similarities_bow[i])[:top_k].tolist()\n",
    "    for i, claim_id in enumerate(test_claims_ids)\n",
    "}\n",
    "\n",
    "test_claims_retrieved_bow = {\n",
    "    claim_id: {\n",
    "        \"claim_text\": test_claims[claim_id]['claim_text'],\n",
    "        \"evidences\": [evidence_ids[i] for i in top_k_evidence_test_bow[claim_id]],\n",
    "    }\n",
    "    for claim_id in test_claims_ids\n",
    "}\n",
    "\n",
    "output_file_bow = os.path.join(DATA_DIR, \"test_claims_retrieved_bow.json\")\n",
    "with open(output_file_bow, 'w') as f:\n",
    "    json.dump(test_claims_retrieved_bow, f, indent=4)\n",
    "\n",
    "print(f\"Test claims with retrieved evidences saved to {output_file_bow}.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
